{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf51455",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "import vr2p\n",
    "import zarr\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "def non_negative(arr):\n",
    "    return np.where(arr < 0, 0, arr)\n",
    "\n",
    "animal_name = 'Tyche-A5-SetA.zarr'\n",
    "animal = animal_name[:8]\n",
    "print(animal)\n",
    "\n",
    "# Load data\n",
    "path = f'/.../Set A/{animal_name}/'\n",
    "data = vr2p.ExperimentData(path)\n",
    "os.makedirs('Figure_3_FINAL', exist_ok=True)\n",
    "# Generate index for days animal is performing Cue Set A only\n",
    "day_count = []\n",
    "for i in range(len(data.signals.multi_session.F)):\n",
    "    if ('Cue Set A' in data.vr[i].trial.set.unique()) and (len(data.vr[i].trial.set.unique())==1):\n",
    "        day_count.append(i)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(max(day_count))\n",
    "\n",
    "# Load stored place field analysis for each day\n",
    "range_A = range(max(day_count)+1)\n",
    "criteria = 'significant'\n",
    "zarr_file = zarr.open(f'/SetA/{animal}-PF.zarr', mode=\"r\")\n",
    "pf_all_Near = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "pf_all_Far = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "binF_Near = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "binF_Far = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "\n",
    "# Perform analysis for a specific session (e.g., session 0)\n",
    "session = 5\n",
    "\n",
    "# Define threshold based on mean and standard deviation\n",
    "threshold_std = 2  # Number of standard deviations above the mean\n",
    "\n",
    "corr_coeffs = []\n",
    "max_amp_diff_scores = []\n",
    "binF_Near_filtered = []\n",
    "binF_Far_filtered = []\n",
    "original_cell_numbers = []\n",
    "\n",
    "# Calculate max amplitude for each cell across all positions for both trial types\n",
    "max_amplitude_Near = np.max(non_negative(binF_Near[session]), axis=1)\n",
    "max_amplitude_Far = np.max(non_negative(binF_Far[session]), axis=1)\n",
    "\n",
    "# Calculate threshold based on mean and standard deviation of activity values for the session\n",
    "activity_values = np.concatenate((binF_Near[session][:, :], binF_Far[session][:, :]))\n",
    "threshold = np.mean(activity_values) + threshold_std * np.std(activity_values)\n",
    "\n",
    "for j in range(len(max_amplitude_Near)):\n",
    "    if max_amplitude_Near[j] >= threshold or max_amplitude_Far[j] >= threshold:\n",
    "        corr_coeff, _ = pearsonr(binF_Near[session][j, :], binF_Far[session][j, :])\n",
    "        corr_coeffs.append(corr_coeff)\n",
    "\n",
    "        max_amp_ratio = max_amplitude_Near[j] / max_amplitude_Far[j]\n",
    "        max_amp_diff_score = 1 - min(max_amp_ratio, 1/max_amp_ratio)\n",
    "        max_amp_diff_scores.append(max_amp_diff_score)\n",
    "\n",
    "        # Append the filtered binF arrays\n",
    "        binF_Near_filtered.append(binF_Near[session][j, :])\n",
    "        binF_Far_filtered.append(binF_Far[session][j, :])\n",
    "\n",
    "        # Store the original cell number\n",
    "        original_cell_numbers.append(j)\n",
    "\n",
    "# Convert the filtered binF arrays to numpy arrays\n",
    "binF_Near_filtered = np.array(binF_Near_filtered)\n",
    "binF_Far_filtered = np.array(binF_Far_filtered)\n",
    "\n",
    "positions = np.linspace(0, 230, binF_Near_filtered.shape[1])\n",
    "\n",
    "# Set the style to \"white\"\n",
    "#sns.set_style(\"white\")\n",
    "\n",
    "# Plot scatter plot with selected cells\n",
    "fig_scatter, ax_scatter = plt.subplots(figsize=(16, 14), dpi=500)\n",
    "sns.scatterplot(x=corr_coeffs, y=max_amp_diff_scores, s=120, color='darkgray', alpha=1, ax=ax_scatter)\n",
    "\n",
    "# Define corr_middle\n",
    "corr_middle = 0.2\n",
    "\n",
    "# Define quadrants and representative cells\n",
    "quadrants = [\n",
    "    (np.array(corr_coeffs) < corr_middle) & (np.array(max_amp_diff_scores) >= 0.5),  # Quadrant 1: Splitter\n",
    "    (np.array(corr_coeffs) >= corr_middle) & (np.array(max_amp_diff_scores) >= 0.5),  # Quadrant 2: Splitter\n",
    "    (np.array(corr_coeffs) < corr_middle) & (np.array(max_amp_diff_scores) < 0.5),  # Quadrant 3: Remapping Splitter\n",
    "    (np.array(corr_coeffs) >= corr_middle) & (np.array(max_amp_diff_scores) < 0.5)  # Quadrant 4: Place Cell\n",
    "]\n",
    "\n",
    "cell_type_names = ['Splitter', 'Splitter', 'Remapping Splitter', 'Place Cell']\n",
    "\n",
    "selected_cells_blue = []\n",
    "for quadrant in quadrants:\n",
    "    if np.sum(quadrant) > 0:\n",
    "        quadrant_cells = np.where(quadrant)[0]\n",
    "        corr_vals = np.array(corr_coeffs)[quadrant_cells]\n",
    "        diff_scores = np.array(max_amp_diff_scores)[quadrant_cells]\n",
    "\n",
    "        # Find the cell with extreme combination of correlation and difference score in each quadrant\n",
    "        distances = [euclidean([corr, diff], [corr_middle, 0.5]) for corr, diff in zip(corr_vals, diff_scores)]\n",
    "        extreme_idx = quadrant_cells[np.argmax(distances)]\n",
    "        selected_cells_blue.append(original_cell_numbers[extreme_idx])\n",
    "\n",
    "\n",
    "# Find cells slightly off-center from the middle of each quadrant for black cells\n",
    "selected_cells_black = []\n",
    "for quadrant in quadrants:\n",
    "    if np.sum(quadrant) > 0:\n",
    "        quadrant_cells = np.where(quadrant)[0]\n",
    "        corr_vals = np.array(corr_coeffs)[quadrant_cells]\n",
    "        diff_scores = np.array(max_amp_diff_scores)[quadrant_cells]\n",
    "\n",
    "        # Find the cell slightly off-center from the middle of each quadrant\n",
    "        distances = [euclidean([corr, diff], [corr_middle, 0.5]) for corr, diff in zip(corr_vals, diff_scores)]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        middle_idx = quadrant_cells[sorted_indices[len(distances) // 20]]  # Select the cell at the 5th percentile\n",
    "        selected_cells_black.append(original_cell_numbers[middle_idx])\n",
    "\n",
    "# Find cells in between the extreme and middle cells for red cells\n",
    "selected_cells_red = []\n",
    "for quadrant in quadrants:\n",
    "    if np.sum(quadrant) > 0:\n",
    "        quadrant_cells = np.where(quadrant)[0]\n",
    "        corr_vals = np.array(corr_coeffs)[quadrant_cells]\n",
    "        diff_scores = np.array(max_amp_diff_scores)[quadrant_cells]\n",
    "\n",
    "        # Find the cell closest to the midpoint between the extreme and middle cells in each quadrant\n",
    "        extreme_idx = selected_cells_blue[len(selected_cells_red)]\n",
    "        middle_idx = selected_cells_black[len(selected_cells_red)]\n",
    "        extreme_corr, extreme_diff = corr_coeffs[original_cell_numbers.index(extreme_idx)], max_amp_diff_scores[original_cell_numbers.index(extreme_idx)]\n",
    "        middle_corr, middle_diff = corr_coeffs[original_cell_numbers.index(middle_idx)], max_amp_diff_scores[original_cell_numbers.index(middle_idx)]\n",
    "        target_corr, target_diff = (extreme_corr + middle_corr) / 2, (extreme_diff + middle_diff) / 2\n",
    "        distances = [euclidean([corr, diff], [target_corr, target_diff]) for corr, diff in zip(corr_vals, diff_scores)]\n",
    "        inner_idx = quadrant_cells[np.argmin(distances)]\n",
    "        selected_cells_red.append(original_cell_numbers[inner_idx])\n",
    "\n",
    "# Blue cells (adding some manual selection)\n",
    "blue_cell_numbers = [1063, 248, selected_cells_blue[2], 2917]\n",
    "blue_cell_indices = [original_cell_numbers.index(cell_number) for cell_number in blue_cell_numbers]\n",
    "\n",
    "# Black cells\n",
    "black_cell_numbers = [selected_cells_black[0], selected_cells_black[1], selected_cells_black[2], selected_cells_black[3]]\n",
    "black_cell_indices = [original_cell_numbers.index(cell_number) for cell_number in black_cell_numbers]\n",
    "\n",
    "\n",
    "# Red cells\n",
    "red_cell_numbers = [selected_cells_red[0], selected_cells_red[1], selected_cells_red[2], 6]\n",
    "red_cell_indices = [original_cell_numbers.index(cell_number) for cell_number in red_cell_numbers]\n",
    "\n",
    "for i, cell_idx in enumerate(blue_cell_indices):\n",
    "    sns.scatterplot(x=[corr_coeffs[cell_idx]], y=[max_amp_diff_scores[cell_idx]], s=300, color='blue', alpha=1, edgecolor='black', linewidth=0.5, ax=ax_scatter)\n",
    "    ax_scatter.annotate(f'Blue {i+1}', (corr_coeffs[cell_idx], max_amp_diff_scores[cell_idx]),\n",
    "                        xytext=(10, 10), textcoords='offset points', fontsize=40, color='blue')\n",
    "\n",
    "for i, cell_idx in enumerate(black_cell_indices):\n",
    "    sns.scatterplot(x=[corr_coeffs[cell_idx]], y=[max_amp_diff_scores[cell_idx]], s=300, color='black', alpha=1, edgecolor='black', linewidth=0.5, ax=ax_scatter)\n",
    "    ax_scatter.annotate(f'Black {i+1}', (corr_coeffs[cell_idx], max_amp_diff_scores[cell_idx]),\n",
    "                        xytext=(10, 10), textcoords='offset points', fontsize=40, color='black')\n",
    "\n",
    "for i, cell_idx in enumerate(red_cell_indices):\n",
    "    sns.scatterplot(x=[corr_coeffs[cell_idx]], y=[max_amp_diff_scores[cell_idx]], s=300, color='red', alpha=1, edgecolor='black', linewidth=0.5, ax=ax_scatter)\n",
    "    ax_scatter.annotate(f'Red {i+1}', (corr_coeffs[cell_idx], max_amp_diff_scores[cell_idx]),\n",
    "                        xytext=(10, 10), textcoords='offset points', fontsize=40, color='red')\n",
    "\n",
    "ax_scatter.set_xlabel('Correlation (Near vs Far Trials)', fontsize=40)\n",
    "ax_scatter.set_ylabel('Difference Score', fontsize=40)\n",
    "ax_scatter.tick_params(axis='both', labelsize=32, width=2, length=10, direction='out')\n",
    "ax_scatter.set_xticks([-0.5, 0, 0.5, 1])  # Set x-axis ticks\n",
    "ax_scatter.set_yticks([0, 0.5, 1])  # Set y-axis ticks\n",
    "ax_scatter.xaxis.set_tick_params(width=2)  # Increase x-axis tick thickness\n",
    "ax_scatter.yaxis.set_tick_params(width=2)  # Increase y-axis tick thickness\n",
    "\n",
    "\n",
    "# Set the xlim and ylim before despine to ensure proper plot boundaries\n",
    "ax_scatter.set_xlim(-0.8, 1)\n",
    "ax_scatter.set_ylim(0, 1)\n",
    "\n",
    "sns.despine(ax=ax_scatter, top=True, right=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)  # Adjust the top spacing to prevent overlapping\n",
    "plt.savefig('Figure_3_FINAL/scatter_plot_selected_cells_square.pdf', dpi=500, bbox_inches='tight')\n",
    "\n",
    "# Define colors for tuning curves\n",
    "near_color = 'orchid'    \n",
    "far_color = 'seagreen'  \n",
    "\n",
    "\n",
    "# Plot tuning curves for the selected cells\n",
    "fig_blue, axs_blue = plt.subplots(2, 2, figsize=(16, 16), dpi=500)\n",
    "axs_blue = axs_blue.flatten()\n",
    "\n",
    "for i, cell_idx in enumerate(blue_cell_indices):\n",
    "    axs_blue[i].plot(positions, binF_Near_filtered[cell_idx, :], label='Near' if i == 0 else '', linestyle='-', color=near_color, linewidth=4)\n",
    "    axs_blue[i].plot(positions, binF_Far_filtered[cell_idx, :], label='Far' if i == 0 else '', linestyle='-', color=far_color, linewidth=4)\n",
    "\n",
    "    axs_blue[i].set_xlabel('Position (cm)', fontsize=32)\n",
    "    axs_blue[i].set_ylabel('Activity (dF/F0)', fontsize=32)\n",
    "    axs_blue[i].set_title(f'Blue {i+1}', fontsize=36, color='blue')\n",
    "    axs_blue[i].tick_params(axis='both', labelsize=28, width=2, length=10, direction='out')\n",
    "    axs_blue[i].set_xticks([0, 50, 100, 150, 200])  # Set x-axis ticks\n",
    "    axs_blue[i].xaxis.set_tick_params(width=2)  # Increase x-axis tick thickness\n",
    "    axs_blue[i].yaxis.set_tick_params(width=2)  # Increase y-axis tick thickness\n",
    "    axs_blue[i].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    if i == 0:\n",
    "        axs_blue[i].legend(fontsize=28, loc='upper right', frameon=False)\n",
    "    sns.despine(ax=axs_blue[i], top=True, right=True)  # Remove top and right axis box\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figure_3_FINAL/tuning_curves_blue_cells.pdf', dpi=500, bbox_inches='tight')\n",
    "\n",
    "fig_black, axs_black = plt.subplots(2, 2, figsize=(16, 16), dpi=500)\n",
    "axs_black = axs_black.flatten()\n",
    "\n",
    "for i, cell_idx in enumerate(black_cell_indices):\n",
    "    axs_black[i].plot(positions, binF_Near_filtered[cell_idx, :], linestyle='-', color=near_color, linewidth=4)\n",
    "    axs_black[i].plot(positions, binF_Far_filtered[cell_idx, :], linestyle='-', color=far_color, linewidth=4)\n",
    "\n",
    "    axs_black[i].set_xlabel('Position (cm)', fontsize=32)\n",
    "    axs_black[i].set_ylabel('Activity (dF/F0)', fontsize=32)\n",
    "    axs_black[i].set_title(f'Black {i+1}', fontsize=36, color='black')\n",
    "    axs_black[i].tick_params(axis='both', labelsize=28, width=2, length=10, direction='out')\n",
    "    axs_black[i].set_xticks([0, 50, 100, 150, 200])  # Set x-axis ticks\n",
    "    axs_black[i].xaxis.set_tick_params(width=2)  # Increase x-axis tick thickness\n",
    "    axs_black[i].yaxis.set_tick_params(width=2)  # Increase y-axis tick thickness\n",
    "    axs_black[i].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    sns.despine(ax=axs_black[i], top=True, right=True)  # Remove top and right axis box\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figure_3_FINAL/tuning_curves_inner_cells.pdf', dpi=500, bbox_inches='tight')\n",
    "\n",
    "fig_red, axs_red = plt.subplots(2, 2, figsize=(16, 16), dpi=500)\n",
    "axs_red = axs_red.flatten()\n",
    "\n",
    "for i, cell_idx in enumerate(red_cell_indices):\n",
    "    axs_red[i].plot(positions, binF_Near_filtered[cell_idx, :], linestyle='-', color=near_color, linewidth=4)\n",
    "    axs_red[i].plot(positions, binF_Far_filtered[cell_idx, :], linestyle='-', color=far_color, linewidth=4)\n",
    "\n",
    "    axs_red[i].set_xlabel('Position (cm)', fontsize=32)\n",
    "    axs_red[i].set_ylabel('Activity (dF/F0)', fontsize=32)\n",
    "    axs_red[i].set_title(f'Red {i+1}', fontsize=36, color='red')\n",
    "    axs_red[i].tick_params(axis='both', labelsize=28, width=2, length=10, direction='out')\n",
    "    axs_red[i].set_xticks([0, 50, 100, 150, 200])  # Set x-axis ticks\n",
    "    axs_red[i].xaxis.set_tick_params(width=2)  # Increase x-axis tick thickness\n",
    "    axs_red[i].yaxis.set_tick_params(width=2)  # Increase y-axis tick thickness\n",
    "    axs_red[i].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    sns.despine(ax=axs_red[i], top=True, right=True)  # Remove top and right axis box\n",
    "    if i == 0:  \n",
    "        axs_red[i].set_ylim(None, 1)  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figure_3_FINAL/tuning_curves_middle_cells.pdf', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "sessions = range_A\n",
    "\n",
    "# Select the first, middle, and last sessions\n",
    "selected_sessions = [sessions[0], sessions[len(sessions)//2], sessions[-1]]\n",
    "\n",
    "# Define markers and their corresponding positions\n",
    "markers = [\n",
    "    {'name': 'Track Boundaries', 'position': [0, 12]},\n",
    "    {'name': 'Track Boundaries', 'position': [40, 46]},\n",
    "    {'name': 'Indicator', 'position': [12, 20]},\n",
    "    {'name': 'Reward / Pre-Reward', 'position': [20, 40]},\n",
    "]\n",
    "\n",
    "# Define colors for each group\n",
    "colors = {\n",
    "    'Track Boundaries': 'black',\n",
    "    'Indicator': 'red',\n",
    "    'Reward / Pre-Reward': 'lightblue',\n",
    "}\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(f'plots/{animal}/New_figure_3', exist_ok=True)\n",
    "\n",
    "# Plot scatter plots of corr vs diff for selected sessions with colored dots\n",
    "fig1, axs1 = plt.subplots(1, len(selected_sessions), figsize=(16, 6), dpi=300)\n",
    "#fig1.suptitle(f'Correlation Coefficient vs Max Amplitude Difference (Scatter Plots)', fontsize=24)\n",
    "\n",
    "for i, session in enumerate(selected_sessions):\n",
    "    corr_coeffs = []\n",
    "    max_amp_diff_scores = []\n",
    "    positions = []\n",
    "\n",
    "    # Calculate max amplitude for each cell across all positions for both trial types\n",
    "    max_amplitude_Near_idx = np.argmax(non_negative(binF_Near[session]), axis=1)\n",
    "    max_amplitude_Far_idx = np.argmax(non_negative(binF_Far[session]), axis=1)\n",
    "\n",
    "    max_amplitude_Near = binF_Near[session][np.arange(len(max_amplitude_Near_idx)), max_amplitude_Near_idx]\n",
    "    max_amplitude_Far = binF_Far[session][np.arange(len(max_amplitude_Far_idx)), max_amplitude_Far_idx]\n",
    "\n",
    "    # Calculate threshold based on mean and standard deviation of activity values for the session\n",
    "    activity_values = np.concatenate((binF_Near[session][:, :], binF_Far[session][:, :]))\n",
    "    threshold = np.mean(activity_values) + threshold_std * np.std(activity_values)\n",
    "\n",
    "    for j in range(len(max_amplitude_Near)):\n",
    "        if max_amplitude_Near[j] >= threshold or max_amplitude_Far[j] >= threshold:\n",
    "            corr_coeff, _ = pearsonr(binF_Near[session][j, :], binF_Far[session][j, :])\n",
    "            corr_coeffs.append(corr_coeff)\n",
    "\n",
    "            max_amp_ratio = max_amplitude_Near[j] / max_amplitude_Far[j]\n",
    "            max_amp_diff_score = 1 - min(max_amp_ratio, 1/max_amp_ratio)\n",
    "            max_amp_diff_scores.append(max_amp_diff_score)\n",
    "\n",
    "            # Get the position of the cell based on the max amplitude index\n",
    "            position = max_amplitude_Near_idx[j] if max_amplitude_Near[j] >= max_amplitude_Far[j] else max_amplitude_Far_idx[j]\n",
    "            positions.append(position)\n",
    "\n",
    "    # Determine the color of each dot based on its position\n",
    "    dot_colors = []\n",
    "    for position in positions:\n",
    "        for marker in markers:\n",
    "            if marker['position'][0] <= position < marker['position'][1]:\n",
    "                dot_colors.append(colors[marker['name']])\n",
    "                break\n",
    "        else:\n",
    "            dot_colors.append('gray')  # Default color if position doesn't fall into any group\n",
    "\n",
    "    # Plot correlation coefficient vs max amplitude difference score (scatter plots)\n",
    "    ax1 = axs1[i]\n",
    "    scatter = ax1.scatter(corr_coeffs, max_amp_diff_scores, s=50, c=dot_colors, edgecolors='black', linewidths=0.5)\n",
    "\n",
    "    ax1.set_xlabel('Corr (Near vs Far Trials)', fontsize=20)\n",
    "    ax1.set_ylabel('Max Amplitude Difference Score', fontsize=20)\n",
    "    ax1.set_title(f'Session {session+1}', fontsize=24)\n",
    "    ax1.tick_params(axis='both', labelsize=18)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust the spacing between subplots\n",
    "plt.savefig(f'plots/{animal}/New_figure_3/{animal}_corr_coeff_vs_max_amp_diff_scatter_plots_color_coded.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Create a separate plot for the legend\n",
    "fig_legend, ax_legend = plt.subplots(figsize=(6, 1), dpi=300)\n",
    "\n",
    "legend_handles = [mlines.Line2D([], [], color=color, marker='o', linestyle='None', markersize=10, label=label) for label, color in colors.items()]\n",
    "ax_legend.legend(handles=legend_handles, loc='center', ncol=len(colors), fontsize=16, frameon=False)\n",
    "\n",
    "ax_legend.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'plots/{animal}/New_figure_3/{animal}_corr_coeff_vs_max_amp_diff_scatter_plots_legend.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9a2bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sessions = range_A\n",
    "# Select the first, middle, and last sessions\n",
    "selected_sessions = [sessions[0], sessions[len(sessions)//2], sessions[-1]]\n",
    "# Define markers and their corresponding positions\n",
    "markers = [\n",
    "    {'name': 'Track Boundaries', 'position': [[0, 12], [40, 46]], 'color': 'gray'},\n",
    "    {'name': 'Indicator', 'position': [12, 20], 'color': 'orange'},\n",
    "    {'name': 'Intra-Track', 'position': [20, 40], 'color': 'mediumturquoise'},\n",
    "]\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(f'plots/{animal}/New_figure_3', exist_ok=True)\n",
    "# Set Seaborn style\n",
    "sns.set(style=\"ticks\")\n",
    "# Plot scatter plots of corr vs diff for selected sessions with colored dots\n",
    "fig1, axs1 = plt.subplots(3, 3, figsize=(16, 16), dpi=500, sharex=True, sharey=True)\n",
    "for i, marker in enumerate(markers):\n",
    "    for j, session in enumerate(selected_sessions):\n",
    "        corr_coeffs = []\n",
    "        max_amp_diff_scores = []\n",
    "        # Calculate max amplitude for each cell across all positions for both trial types\n",
    "        max_amplitude_Near_idx = np.argmax(non_negative(binF_Near[session]), axis=1)\n",
    "        max_amplitude_Far_idx = np.argmax(non_negative(binF_Far[session]), axis=1)\n",
    "        max_amplitude_Near = binF_Near[session][np.arange(len(max_amplitude_Near_idx)), max_amplitude_Near_idx]\n",
    "        max_amplitude_Far = binF_Far[session][np.arange(len(max_amplitude_Far_idx)), max_amplitude_Far_idx]\n",
    "        # Calculate threshold based on mean and standard deviation of activity values for the session\n",
    "        activity_values = np.concatenate((binF_Near[session][:, :], binF_Far[session][:, :]))\n",
    "        threshold = np.mean(activity_values) + threshold_std * np.std(activity_values)\n",
    "        for k in range(len(max_amplitude_Near)):\n",
    "            if max_amplitude_Near[k] >= threshold or max_amplitude_Far[k] >= threshold:\n",
    "                corr_coeff, _ = pearsonr(binF_Near[session][k, :], binF_Far[session][k, :])\n",
    "                corr_coeffs.append(corr_coeff)\n",
    "                max_amp_ratio = max_amplitude_Near[k] / max_amplitude_Far[k]\n",
    "                max_amp_diff_score = 1 - min(max_amp_ratio, 1/max_amp_ratio)\n",
    "                max_amp_diff_scores.append(max_amp_diff_score)\n",
    "                # Get the position of the cell based on the max amplitude index\n",
    "                position = max_amplitude_Near_idx[k] if max_amplitude_Near[k] >= max_amplitude_Far[k] else max_amplitude_Far_idx[k]\n",
    "                # Check if the position falls into the current marker's range\n",
    "                if marker['name'] == 'Track Boundaries':\n",
    "                    if any(start <= position < end for start, end in marker['position']):\n",
    "                        # Plot correlation coefficient vs max amplitude difference score (scatter plots)\n",
    "                        ax1 = axs1[i, j]\n",
    "                        ax1.scatter(corr_coeff, max_amp_diff_score, s=80, c=marker['color'], alpha=0.8)\n",
    "                else:\n",
    "                    if marker['position'][0] <= position < marker['position'][1]:\n",
    "                        # Plot correlation coefficient vs max amplitude difference score (scatter plots)\n",
    "                        ax1 = axs1[i, j]\n",
    "                        ax1.scatter(corr_coeff, max_amp_diff_score, s=80, c=marker['color'], alpha=0.8)\n",
    "                ax1.spines['right'].set_visible(False)\n",
    "                ax1.spines['top'].set_visible(False)\n",
    "# Set x-axis range and tick intervals for all subplots\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs1[i, j].set_xlim(-0.8, 1)\n",
    "        axs1[i, j].set_xticks([-0.5, 0, 0.5, 1])\n",
    "        axs1[i, j].set_xticklabels([-0.5, 0, 0.5, 1], fontsize=12)  # Set x-tick labels explicitly\n",
    "        axs1[i, j].set_yticks([0, 0.5, 1])\n",
    "        axs1[i, j].tick_params(axis='both', labelsize=12, width=2, length=6)\n",
    "        axs1[i, j].spines['bottom'].set_visible(True)\n",
    "        axs1[i, j].spines['left'].set_visible(True)\n",
    "        ylim = axs1[i, j].get_ylim()\n",
    "        print(f\"Subplot ({i}, {j}) - Y-axis limits: {ylim}\")\n",
    "\n",
    "# Add y-axis labels for the subplots in the first column\n",
    "for i in range(3):\n",
    "    axs1[i, 0].set_ylabel('Difference Score', fontsize=14)\n",
    "# Add x-axis labels for the subplots in the last row\n",
    "for j in range(3):\n",
    "    axs1[2, j].set_xlabel('Correlation (Near vs Far Trials)', fontsize=14)\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "plt.savefig(f'Figure_3_FINAL/{animal}_corr_coeff_vs_max_amp_diff_scatter_plots_color_coded_separate_merged_seaborn_modified_4.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.interpolate import interp1d\n",
    "import vr2p\n",
    "import zarr\n",
    "\n",
    "def non_negative(arr):\n",
    "    return np.where(arr < 0, 0, arr)\n",
    "\n",
    "def calculate_percentages(corr_coeffs, max_amp_diff_scores, threshold=0.2):\n",
    "    quadrants = [\n",
    "        (np.array(corr_coeffs) < threshold) & (np.array(max_amp_diff_scores) >= 0.5),  # Quadrant 1: Strong Splitter\n",
    "        (np.array(corr_coeffs) >= threshold) & (np.array(max_amp_diff_scores) >= 0.5),  # Quadrant 2: Weak Splitter\n",
    "        (np.array(corr_coeffs) < threshold) & (np.array(max_amp_diff_scores) < 0.5),  # Quadrant 3: Multiplex Splitter\n",
    "        (np.array(corr_coeffs) >= threshold) & (np.array(max_amp_diff_scores) < 0.5)  # Quadrant 4: Place Cell\n",
    "    ]\n",
    "\n",
    "    percentages = [np.sum(quadrant) / len(corr_coeffs) * 100 for quadrant in quadrants]\n",
    "    return percentages\n",
    "\n",
    "# Check if the variables are already saved\n",
    "if os.path.exists('plots/interp_sessions.npy') and os.path.exists('plots/mean_percentages.npy') and os.path.exists('plots/sem_percentages.npy'):\n",
    "    # Load the saved variables\n",
    "    interp_sessions = np.load('plots/interp_sessions.npy')\n",
    "    mean_percentages = np.load('plots/mean_percentages.npy')\n",
    "    sem_percentages = np.load('plots/sem_percentages.npy')\n",
    "else:\n",
    "    # Get the list of animal names\n",
    "    names = os.listdir('/.../Set A/')\n",
    "    names = [name for name in names if name != '.DS_Store']\n",
    "\n",
    "    all_percentages = []\n",
    "\n",
    "    for animal_name in names:\n",
    "        animal = animal_name[:8]\n",
    "        print(f\"Processing animal: {animal}\")\n",
    "\n",
    "        # Create a directory for the animal's plots\n",
    "        os.makedirs(f'plots/{animal}', exist_ok=True)\n",
    "\n",
    "        # Load data\n",
    "        path = f'/.../Set A/{animal_name}/'\n",
    "        data = vr2p.ExperimentData(path)\n",
    "\n",
    "        # Generate index for days animal is performing Cue Set A only\n",
    "        day_count = []\n",
    "        for i in range(len(data.signals.multi_session.F)):\n",
    "            if ('Cue Set A' in data.vr[i].trial.set.unique()) and (len(data.vr[i].trial.set.unique())==1):\n",
    "                day_count.append(i)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        print(max(day_count))\n",
    "\n",
    "        # Load stored place field analysis for each day\n",
    "        range_A = range(max(day_count)+1)\n",
    "        criteria = 'significant'\n",
    "        zarr_file = zarr.open(f'/SetA/{animal}-PF.zarr', mode=\"r\")\n",
    "        pf_all_Near = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "        pf_all_Far = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "        binF_Near = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "        binF_Far = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "\n",
    "        sessions = range_A\n",
    "\n",
    "        # Define markers and their corresponding positions\n",
    "        markers = [\n",
    "            {'name': 'Track Boundaries', 'position': [0, 12]},\n",
    "            {'name': 'Track Boundaries', 'position': [40, 46]},\n",
    "            {'name': 'Indicator', 'position': [12, 20]},\n",
    "            {'name': 'Intra-Track', 'position': [20, 40]},\n",
    "        ]\n",
    "\n",
    "        # Define colors for each group\n",
    "        colors = {\n",
    "            'Track Boundaries': 'black',\n",
    "            'Indicator': 'red',\n",
    "            'Intra-Track': 'lightblue',\n",
    "        }\n",
    "\n",
    "        # Define threshold based on mean and standard deviation\n",
    "        threshold_std = 2  # Number of standard deviations above the mean\n",
    "\n",
    "        percentage_data = []\n",
    "\n",
    "        for session in sessions:\n",
    "            corr_coeffs = []\n",
    "            max_amp_diff_scores = []\n",
    "            positions = []\n",
    "\n",
    "            # Calculate max amplitude for each cell across all positions for both trial types\n",
    "            max_amplitude_Near_idx = np.argmax(non_negative(binF_Near[session]), axis=1)\n",
    "            max_amplitude_Far_idx = np.argmax(non_negative(binF_Far[session]), axis=1)\n",
    "\n",
    "            max_amplitude_Near = binF_Near[session][np.arange(len(max_amplitude_Near_idx)), max_amplitude_Near_idx]\n",
    "            max_amplitude_Far = binF_Far[session][np.arange(len(max_amplitude_Far_idx)), max_amplitude_Far_idx]\n",
    "\n",
    "            # Calculate threshold based on mean and standard deviation of activity values for the session\n",
    "            activity_values = np.concatenate((binF_Near[session][:, :], binF_Far[session][:, :]))\n",
    "            threshold = np.mean(activity_values) + threshold_std * np.std(activity_values)\n",
    "\n",
    "            for j in range(len(max_amplitude_Near)):\n",
    "                if max_amplitude_Near[j] >= threshold or max_amplitude_Far[j] >= threshold:\n",
    "                    corr_coeff, _ = pearsonr(binF_Near[session][j, :], binF_Far[session][j, :])\n",
    "                    corr_coeffs.append(corr_coeff)\n",
    "\n",
    "                    max_amp_ratio = max_amplitude_Near[j] / max_amplitude_Far[j]\n",
    "                    max_amp_diff_score = 1 - min(max_amp_ratio, 1/max_amp_ratio)\n",
    "                    max_amp_diff_scores.append(max_amp_diff_score)\n",
    "\n",
    "                    # Get the position of the cell based on the max amplitude index\n",
    "                    position = max_amplitude_Near_idx[j] if max_amplitude_Near[j] >= max_amplitude_Far[j] else max_amplitude_Far_idx[j]\n",
    "                    positions.append(position)\n",
    "\n",
    "            # Calculate the percentages for each quadrant\n",
    "            percentages = calculate_percentages(corr_coeffs, max_amp_diff_scores, threshold=0.2)\n",
    "            percentage_data.append(percentages)\n",
    "\n",
    "        all_percentages.append(percentage_data)\n",
    "\n",
    "        # Plot the percentage changes for each quadrant over sessions for the current animal\n",
    "        fig_animal, ax_animal = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "\n",
    "        for i, quadrant in enumerate(['Q1: Strong Splitter', 'Q2: Weak Splitter', 'Q3: Multiplex Splitter', 'Q4: Place Cell']):\n",
    "            percentages = [data[i] for data in percentage_data]\n",
    "            ax_animal.plot(range(1, len(sessions) + 1), percentages, marker='o', label=quadrant, linewidth=2)\n",
    "\n",
    "        ax_animal.set_xlabel('Session', fontsize=14, fontweight='bold')\n",
    "        ax_animal.set_ylabel('Percentage (%)', fontsize=14, fontweight='bold')\n",
    "        ax_animal.set_title(f'Percentage of Cell Types Across Sessions ({animal})', fontsize=16, fontweight='bold')\n",
    "        ax_animal.tick_params(axis='both', labelsize=14)\n",
    "        ax_animal.spines['top'].set_visible(False)\n",
    "        ax_animal.spines['right'].set_visible(False)\n",
    "        ax_animal.legend(fontsize=12, frameon=False, loc='upper left')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'plots/{animal}/{animal}_percentage_changes.pdf', dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig_animal)\n",
    "\n",
    "    # Normalize session numbers and interpolate data\n",
    "    normalized_percentages = []\n",
    "    max_sessions = max(len(data) for data in all_percentages)\n",
    "\n",
    "    for data in all_percentages:\n",
    "        sessions = np.linspace(0, 1, len(data))\n",
    "        interp_sessions = np.linspace(0, 1, max_sessions)\n",
    "        interp_data = []\n",
    "\n",
    "        for i in range(4):\n",
    "            interp_func = interp1d(sessions, [d[i] for d in data], kind='linear')\n",
    "            interp_data.append(interp_func(interp_sessions))\n",
    "\n",
    "        normalized_percentages.append(interp_data)\n",
    "\n",
    "    # Calculate mean and SEM across animals\n",
    "    mean_percentages = np.mean(normalized_percentages, axis=0)\n",
    "    sem_percentages = np.std(normalized_percentages, axis=0) / np.sqrt(len(normalized_percentages))\n",
    "\n",
    "    # Save variables for replotting\n",
    "    np.save('plots/interp_sessions.npy', interp_sessions)\n",
    "    np.save('plots/mean_percentages.npy', mean_percentages)\n",
    "    np.save('plots/sem_percentages.npy', sem_percentages)\n",
    "\n",
    "# Create a figure and axis for the summary plot\n",
    "fig_summary, ax_summary = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "\n",
    "# Plot the mean percentage changes for each quadrant with SEM shading\n",
    "for i, quadrant in enumerate(['Q1: Strong Splitter', 'Q2: Weak Splitter', 'Q3: Multiplex Splitter', 'Q4: Place Cell']):\n",
    "    ax_summary.plot(interp_sessions, mean_percentages[i], marker='o', label=quadrant, linewidth=2)\n",
    "    ax_summary.fill_between(interp_sessions, mean_percentages[i] - sem_percentages[i], mean_percentages[i] + sem_percentages[i],\n",
    "                            alpha=0.3, edgecolor='none')\n",
    "\n",
    "# Set axis labels and title for the summary plot\n",
    "ax_summary.set_xlabel('Normalized Session', fontsize=14, fontweight='bold')\n",
    "ax_summary.set_ylabel('Percentage (%)', fontsize=14, fontweight='bold')\n",
    "ax_summary.set_title('Percentage of Cell Types Across Sessions (All Animals)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Set tick parameters and remove top and right spines for the summary plot\n",
    "ax_summary.tick_params(axis='both', labelsize=14)\n",
    "ax_summary.spines['top'].set_visible(False)\n",
    "ax_summary.spines['right'].set_visible(False)\n",
    "\n",
    "# Add legend for the summary plot\n",
    "ax_summary.legend(fontsize=12, frameon=False, loc='upper left')\n",
    "\n",
    "# Adjust layout and save the summary plot\n",
    "plt.tight_layout()\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "plt.savefig('plots/all_animals_percentage_changes_summary.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e83616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.interpolate import interp1d\n",
    "import vr2p\n",
    "import zarr\n",
    "\n",
    "def non_negative(arr):\n",
    "    return np.where(arr < 0, 0, arr)\n",
    "\n",
    "def calculate_percentages(corr_coeffs, max_amp_diff_scores, threshold=0.2):\n",
    "    quadrants = [\n",
    "        np.array(max_amp_diff_scores) >= 0.5,  # Splitter (Strong and Weak combined)\n",
    "        (np.array(corr_coeffs) < threshold) & (np.array(max_amp_diff_scores) < 0.5),  # Multiplex Splitter\n",
    "        (np.array(corr_coeffs) >= threshold) & (np.array(max_amp_diff_scores) < 0.5)  # Place Cell\n",
    "    ]\n",
    "\n",
    "    percentages = [np.sum(quadrant) / len(corr_coeffs) * 100 for quadrant in quadrants]\n",
    "    return percentages\n",
    "\n",
    "# Get the list of animal names\n",
    "names = os.listdir('/.../Set A/')\n",
    "names = [name for name in names if name != '.DS_Store']\n",
    "\n",
    "all_percentages = []\n",
    "\n",
    "for animal_name in names:\n",
    "    animal = animal_name[:8]\n",
    "    print(f\"Processing animal: {animal}\")\n",
    "\n",
    "    # Create a directory for the animal's plots\n",
    "    os.makedirs(f'plots/{animal}', exist_ok=True)\n",
    "\n",
    "    # Load data\n",
    "    path = f'/.../Set A/{animal_name}/'\n",
    "    data = vr2p.ExperimentData(path)\n",
    "\n",
    "    # Generate index for days animal is performing Cue Set A only\n",
    "    day_count = []\n",
    "    for i in range(len(data.signals.multi_session.F)):\n",
    "        if ('Cue Set A' in data.vr[i].trial.set.unique()) and (len(data.vr[i].trial.set.unique())==1):\n",
    "            day_count.append(i)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(max(day_count))\n",
    "\n",
    "    # Load stored place field analysis for each day\n",
    "    range_A = range(max(day_count)+1)\n",
    "    criteria = 'significant'\n",
    "    zarr_file = zarr.open(f'/SetA/{animal}-PF.zarr', mode=\"r\")\n",
    "    pf_all_Near = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "    pf_all_Far = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "    binF_Near = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "    binF_Far = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "\n",
    "    sessions = range_A\n",
    "\n",
    "    # Define threshold based on mean and standard deviation\n",
    "    threshold_std = 2  # Number of standard deviations above the mean\n",
    "\n",
    "    percentage_data = []\n",
    "\n",
    "    for session in sessions:\n",
    "        corr_coeffs = []\n",
    "        max_amp_diff_scores = []\n",
    "\n",
    "        # Calculate max amplitude for each cell across all positions for both trial types\n",
    "        max_amplitude_Near_idx = np.argmax(non_negative(binF_Near[session]), axis=1)\n",
    "        max_amplitude_Far_idx = np.argmax(non_negative(binF_Far[session]), axis=1)\n",
    "\n",
    "        max_amplitude_Near = binF_Near[session][np.arange(len(max_amplitude_Near_idx)), max_amplitude_Near_idx]\n",
    "        max_amplitude_Far = binF_Far[session][np.arange(len(max_amplitude_Far_idx)), max_amplitude_Far_idx]\n",
    "\n",
    "        # Calculate threshold based on mean and standard deviation of activity values for the session\n",
    "        activity_values = np.concatenate((binF_Near[session][:, :], binF_Far[session][:, :]))\n",
    "        threshold = np.mean(activity_values) + threshold_std * np.std(activity_values)\n",
    "\n",
    "        for j in range(len(max_amplitude_Near)):\n",
    "            if max_amplitude_Near[j] >= threshold or max_amplitude_Far[j] >= threshold:\n",
    "                corr_coeff, _ = pearsonr(binF_Near[session][j, :], binF_Far[session][j, :])\n",
    "                corr_coeffs.append(corr_coeff)\n",
    "\n",
    "                max_amp_ratio = max_amplitude_Near[j] / max_amplitude_Far[j]\n",
    "                max_amp_diff_score = 1 - min(max_amp_ratio, 1/max_amp_ratio)\n",
    "                max_amp_diff_scores.append(max_amp_diff_score)\n",
    "\n",
    "        # Calculate the percentages for each quadrant\n",
    "        percentages = calculate_percentages(corr_coeffs, max_amp_diff_scores, threshold=0.2)\n",
    "        percentage_data.append(percentages)\n",
    "\n",
    "    all_percentages.append(percentage_data)\n",
    "\n",
    "    # Plot the percentage changes for each quadrant over sessions for the current animal\n",
    "    fig_animal, ax_animal = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "\n",
    "    for i, quadrant in enumerate(['Splitter', 'Multiplex Splitter', 'Place Cell']):\n",
    "        percentages = [data[i] for data in percentage_data]\n",
    "        ax_animal.plot(range(1, len(sessions) + 1), percentages, marker='o', label=quadrant, linewidth=2)\n",
    "\n",
    "    ax_animal.set_xlabel('Session', fontsize=14, fontweight='bold')\n",
    "    ax_animal.set_ylabel('Percentage (%)', fontsize=14, fontweight='bold')\n",
    "    ax_animal.set_title(f'Percentage of Cell Types Across Sessions ({animal})', fontsize=16, fontweight='bold')\n",
    "    ax_animal.tick_params(axis='both', labelsize=14)\n",
    "    ax_animal.spines['top'].set_visible(False)\n",
    "    ax_animal.spines['right'].set_visible(False)\n",
    "    ax_animal.legend(fontsize=12, frameon=False, loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/{animal}/{animal}_percentage_changes.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig_animal)\n",
    "\n",
    "# Normalize session numbers and interpolate data\n",
    "normalized_percentages = []\n",
    "max_sessions = max(len(data) for data in all_percentages)\n",
    "\n",
    "for data in all_percentages:\n",
    "    sessions = np.linspace(0, 1, len(data))\n",
    "    interp_sessions = np.linspace(0, 1, max_sessions)\n",
    "    interp_data = []\n",
    "\n",
    "    for i in range(3):\n",
    "        interp_func = interp1d(sessions, [d[i] for d in data], kind='linear')\n",
    "        interp_data.append(interp_func(interp_sessions))\n",
    "\n",
    "    normalized_percentages.append(interp_data)\n",
    "\n",
    "# Calculate mean and SEM across animals\n",
    "mean_percentages = np.mean(normalized_percentages, axis=0)\n",
    "sem_percentages = np.std(normalized_percentages, axis=0) / np.sqrt(len(normalized_percentages))\n",
    "\n",
    "# Create a figure and axis for the summary plot\n",
    "fig_summary, ax_summary = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "\n",
    "# Plot the mean percentage changes for each quadrant with SEM shading\n",
    "for i, quadrant in enumerate(['Splitter', 'Multiplex Splitter', 'Place Cell']):\n",
    "    ax_summary.plot(interp_sessions, mean_percentages[i], marker='o', label=quadrant, linewidth=2)\n",
    "    ax_summary.fill_between(interp_sessions, mean_percentages[i] - sem_percentages[i], mean_percentages[i] + sem_percentages[i],\n",
    "                            alpha=0.3, edgecolor='none')\n",
    "\n",
    "# Set axis labels and title for the summary plot\n",
    "ax_summary.set_xlabel('Normalized Session', fontsize=14, fontweight='bold')\n",
    "ax_summary.set_ylabel('Percentage (%)', fontsize=14, fontweight='bold')\n",
    "ax_summary.set_title('Percentage of Cell Types Across Sessions (All Animals)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Set tick parameters and remove top and right spines for the summary plot\n",
    "ax_summary.tick_params(axis='both', labelsize=14)\n",
    "ax_summary.spines['top'].set_visible(False)\n",
    "ax_summary.spines['right'].set_visible(False)\n",
    "\n",
    "# Add legend for the summary plot\n",
    "ax_summary.legend(fontsize=12, frameon=False, loc='upper left')\n",
    "\n",
    "# Adjust layout and save the summary plot\n",
    "plt.tight_layout()\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "plt.savefig('plots/all_animals_percentage_changes_summary.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24d086",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Create a figure and axis for the summary plot\n",
    "fig_summary, ax_summary = plt.subplots(figsize=(6, 6), dpi=300)\n",
    "\n",
    "# Define colors for each category\n",
    "colors = ['chocolate', 'mediumseagreen','slategray' ]\n",
    "\n",
    "# Plot the mean percentage changes for each quadrant with SEM shading\n",
    "for i, quadrant in enumerate(['Splitter', 'Multiplex Splitter', 'Place Cell']):\n",
    "    ax_summary.plot(interp_sessions, mean_percentages[i], marker='o', label=quadrant, linewidth=2, color=colors[i])\n",
    "    ax_summary.fill_between(interp_sessions, mean_percentages[i] - sem_percentages[i], mean_percentages[i] + sem_percentages[i],\n",
    "                            alpha=0.3, color=colors[i], edgecolor='none')\n",
    "\n",
    "# Set axis labels and title for the summary plot\n",
    "ax_summary.set_xlabel('Normalized Training Time', fontsize=16)\n",
    "ax_summary.set_ylabel('Percentage (%)', fontsize=16)\n",
    "#ax_summary.set_title('Percentage of Cell Types Across Sessions (All Animals)', fontsize=18)\n",
    "\n",
    "# Set tick parameters and remove top and right spines for the summary plot\n",
    "ax_summary.tick_params(axis='both', labelsize=14)\n",
    "ax_summary.spines['top'].set_visible(False)\n",
    "ax_summary.spines['right'].set_visible(False)\n",
    "\n",
    "# Add axis tick marks\n",
    "ax_summary.xaxis.set_ticks_position('bottom')\n",
    "ax_summary.yaxis.set_ticks_position('left')\n",
    "\n",
    "# Adjust layout and save the summary plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figure_3_FINAL//all_animals_percentage_changes_summary_colored.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Create a separate figure for the custom legend\n",
    "fig_legend, ax_legend = plt.subplots(figsize=(3, 3), dpi=300)\n",
    "ax_legend.axis('off')\n",
    "\n",
    "ax_legend.add_patch(Rectangle((0, 0.5), 1, 0.5, facecolor='chocolate'))\n",
    "ax_legend.text(0.5, 0.75, 'S', ha='center', va='center', fontsize=36)\n",
    "\n",
    "ax_legend.add_patch(Rectangle((0, 0), 0.5, 0.5, facecolor='mediumseagreen'))\n",
    "ax_legend.text(0.25, 0.25, 'RS', ha='center', va='center', fontsize=36)\n",
    "\n",
    "ax_legend.add_patch(Rectangle((0.5, 0), 0.5, 0.5, facecolor='slategray'))\n",
    "ax_legend.text(0.75, 0.25, 'P\\n/P-S', ha='center', va='center', fontsize=36)\n",
    "\n",
    "# Adjust layout and save the legend plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figure_3_FINAL/legend_plot.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e898567",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import vr2p\n",
    "import zarr\n",
    "\n",
    "def non_negative(arr):\n",
    "    return np.where(arr < 0, 0, arr)\n",
    "\n",
    "def calculate_percentages(corr_coeffs, max_amp_diff_scores, threshold=0.2):\n",
    "    quadrants = [\n",
    "        np.array(max_amp_diff_scores) >= 0.5,  # Splitter (Strong and Weak combined)\n",
    "        (np.array(corr_coeffs) < threshold) & (np.array(max_amp_diff_scores) < 0.5),  # Multiplex Splitter\n",
    "        (np.array(corr_coeffs) >= threshold) & (np.array(max_amp_diff_scores) < 0.5)  # Place Cell\n",
    "    ]\n",
    "\n",
    "    percentages = [np.sum(quadrant) / len(corr_coeffs) * 100 for quadrant in quadrants]\n",
    "    return percentages\n",
    "\n",
    "# Get the list of animal names\n",
    "names = os.listdir('/.../Set A/')\n",
    "names = [name for name in names if name != '.DS_Store']\n",
    "\n",
    "all_percentages = []\n",
    "\n",
    "for animal_name in names:\n",
    "    animal = animal_name[:8]\n",
    "    print(f\"Processing animal: {animal}\")\n",
    "\n",
    "    # Load data\n",
    "    path = f'/.../Set A/{animal_name}/'\n",
    "    data = vr2p.ExperimentData(path)\n",
    "\n",
    "    # Generate index for days animal is performing Cue Set A only\n",
    "    day_count = []\n",
    "    for i in range(len(data.signals.multi_session.F)):\n",
    "        if ('Cue Set A' in data.vr[i].trial.set.unique()) and (len(data.vr[i].trial.set.unique())==1):\n",
    "            day_count.append(i)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(max(day_count))\n",
    "\n",
    "    # Load stored place field analysis for the last session\n",
    "    last_session = max(day_count)\n",
    "    criteria = 'significant'\n",
    "    zarr_file = zarr.open(f'/SetA/{animal}-PF.zarr', mode=\"r\")\n",
    "    binF_Near = zarr_file[f'Cue Set A/1/excl_no_response/{last_session}/{criteria}'][()]['binF']\n",
    "    binF_Far = zarr_file[f'Cue Set A/2/excl_no_response/{last_session}/{criteria}'][()]['binF']\n",
    "\n",
    "    # Define threshold based on mean and standard deviation\n",
    "    threshold_std = 2  # Number of standard deviations above the mean\n",
    "\n",
    "    # Calculate threshold based on mean and standard deviation of activity values for the session\n",
    "    activity_values = np.concatenate((binF_Near[:, :], binF_Far[:, :]))\n",
    "    threshold = np.mean(activity_values) + threshold_std * np.std(activity_values)\n",
    "\n",
    "    # Find max peak position for each cell\n",
    "    max_peak_positions = np.argmax(np.maximum(non_negative(binF_Near), non_negative(binF_Far)), axis=1)\n",
    "\n",
    "    percentage_data = np.zeros((binF_Near.shape[1], 3))\n",
    "\n",
    "    for position in range(binF_Near.shape[1]):\n",
    "        corr_coeffs = []\n",
    "        max_amp_diff_scores = []\n",
    "\n",
    "        for j in range(len(max_peak_positions)):\n",
    "            if max_peak_positions[j] == position:\n",
    "                if np.max(binF_Near[j, :]) >= threshold or np.max(binF_Far[j, :]) >= threshold:\n",
    "                    corr_coeff, _ = pearsonr(binF_Near[j, :], binF_Far[j, :])\n",
    "                    corr_coeffs.append(corr_coeff)\n",
    "\n",
    "                    max_amp_ratio = np.max(binF_Near[j, :]) / np.max(binF_Far[j, :])\n",
    "                    max_amp_diff_score = 1 - min(max_amp_ratio, 1/max_amp_ratio)\n",
    "                    max_amp_diff_scores.append(max_amp_diff_score)\n",
    "\n",
    "        # Calculate the percentages for each quadrant at the current position\n",
    "        if len(corr_coeffs) > 0:\n",
    "            percentages = calculate_percentages(corr_coeffs, max_amp_diff_scores, threshold=0.2)\n",
    "            percentage_data[position, :] = percentages\n",
    "\n",
    "    all_percentages.append(percentage_data)\n",
    "\n",
    "# Calculate mean and SEM across animals\n",
    "mean_percentages = np.nanmean(all_percentages, axis=0)\n",
    "sem_percentages = np.nanstd(all_percentages, axis=0) / np.sqrt(len(all_percentages))\n",
    "\n",
    "# Create a figure and axis for the position vs percentage plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n",
    "\n",
    "# Plot the mean percentage for each quadrant along positions with SEM shading\n",
    "positions = np.arange(1, 47)  # Assuming 46 position bins\n",
    "for i, quadrant in enumerate(['Splitter', 'Multiplex Splitter', 'Place Cell']):\n",
    "    ax.plot(positions, mean_percentages[:, i], marker='o', label=quadrant, linewidth=2)\n",
    "    ax.fill_between(positions, mean_percentages[:, i] - sem_percentages[:, i], mean_percentages[:, i] + sem_percentages[:, i],\n",
    "                    alpha=0.3, edgecolor='none')\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Position', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Percentage (%)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Percentage of Cell Types Along Positions (Last Session, All Animals)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Set tick parameters and remove top and right spines\n",
    "ax.tick_params(axis='both', labelsize=14)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(fontsize=12, frameon=False, loc='upper left')\n",
    "\n",
    "# Adjust layout and save the plot\n",
    "plt.tight_layout()\n",
    "#os.makedirs('plots', exist_ok=True)\n",
    "#plt.savefig('plots/all_animals_percentage_along_positions.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c232e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Create a figure and axis for the position vs percentage plot\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=300)\n",
    "\n",
    "# Define colors for each category\n",
    "colors = ['chocolate', 'mediumseagreen','slategray' ]\n",
    "\n",
    "# Plot the mean percentage for each quadrant along positions with SEM shading\n",
    "positions = np.arange(1, 47)*5  # Assuming 46 position bins\n",
    "for i, quadrant in enumerate(['Splitter', 'Multiplex Splitter', 'Place Cell']):\n",
    "    ax.plot(positions, mean_percentages[:, i], marker='o', label=quadrant, linewidth=2, color=colors[i])\n",
    "    ax.fill_between(positions, mean_percentages[:, i] - sem_percentages[:, i], mean_percentages[:, i] + sem_percentages[:, i],\n",
    "                    alpha=0.3, color=colors[i], edgecolor='none')\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Position (cm)', fontsize=16)\n",
    "ax.set_ylabel('Percentage (%)', fontsize=16)\n",
    "#ax.set_title('Percentage of Cell Types Along Positions (Last Session, All Animals)', fontsize=18)\n",
    "\n",
    "# Set y-axis range from 0 to 100\n",
    "ax.set_ylim(-5, 105)\n",
    "\n",
    "# Set tick parameters and remove top and right spines\n",
    "ax.tick_params(axis='both', labelsize=14)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Add axis tick marks\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# Adjust layout and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figure_3_FINAL/all_animals_percentage_along_positions_colored.pdf', dpi=300, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabbd86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import vr2p\n",
    "import zarr\n",
    "\n",
    "def non_negative(arr):\n",
    "    return np.where(arr < 0, 0, arr)\n",
    "\n",
    "# Get the list of animal names\n",
    "names = os.listdir('/.../Set A/')\n",
    "names = [name for name in names if name != '.DS_Store']\n",
    "\n",
    "# Define the cell types and their corresponding positions\n",
    "cell_types = [\n",
    "    {'name': 'Track Boundary', 'position': [(0, 12), (40, 46)]},\n",
    "    {'name': 'Intra-Track', 'position': [(20, 40)]},\n",
    "    {'name': 'Indicator', 'position': [(12, 20)]},\n",
    "]\n",
    "\n",
    "# Create a directory to save the data and plots\n",
    "os.makedirs('plots/heatmaps', exist_ok=True)\n",
    "\n",
    "for cell_type in cell_types:\n",
    "    # Check if the data file exists\n",
    "    data_file = f'plots/heatmaps/heatmap_data_{cell_type[\"name\"]}.npz'\n",
    "    if os.path.exists(data_file):\n",
    "        # Load the saved data\n",
    "        loaded_data = np.load(data_file)\n",
    "        avg_heatmap_first = loaded_data['avg_heatmap_first']\n",
    "        avg_heatmap_middle = loaded_data['avg_heatmap_middle']\n",
    "        avg_heatmap_last = loaded_data['avg_heatmap_last']\n",
    "    else:\n",
    "        # Initialize variables to store heatmaps for each session and cell type\n",
    "        heatmaps_first = []\n",
    "        heatmaps_middle = []\n",
    "        heatmaps_last = []\n",
    "\n",
    "        for animal_name in names:\n",
    "            animal = animal_name[:8]\n",
    "            print(f\"Processing animal: {animal}\")\n",
    "\n",
    "            # Load data\n",
    "            path = f'/.../Set A/{animal_name}/'\n",
    "            data = vr2p.ExperimentData(path)\n",
    "\n",
    "            # Generate index for days animal is performing Cue Set A only\n",
    "            day_count = []\n",
    "            for i in range(len(data.signals.multi_session.F)):\n",
    "                if ('Cue Set A' in data.vr[i].trial.set.unique()) and (len(data.vr[i].trial.set.unique())==1):\n",
    "                    day_count.append(i)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            print(max(day_count))\n",
    "\n",
    "            # Load stored place field analysis for each day\n",
    "            range_A = range(max(day_count)+1)\n",
    "            criteria = 'significant'\n",
    "            zarr_file = zarr.open(f'/SetA/{animal}-PF.zarr', mode=\"r\")\n",
    "            pf_all_Near = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "            pf_all_Far = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "            binF_Near = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "            binF_Far = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "\n",
    "            sessions = range_A\n",
    "\n",
    "            # Define threshold based on mean and standard deviation\n",
    "            threshold_std = 2  # Number of standard deviations above the mean\n",
    "\n",
    "            for session in [sessions[0], sessions[len(sessions)//2], sessions[-1]]:\n",
    "                corr_coeffs = []\n",
    "                max_amp_diff_scores = []\n",
    "                positions = []\n",
    "\n",
    "                # Calculate max amplitude and positions for each cell\n",
    "                max_amplitude_Near_idx = np.argmax(non_negative(binF_Near[session]), axis=1)\n",
    "                max_amplitude_Far_idx = np.argmax(non_negative(binF_Far[session]), axis=1)\n",
    "                max_amplitude_Near = binF_Near[session][np.arange(len(max_amplitude_Near_idx)), max_amplitude_Near_idx]\n",
    "                max_amplitude_Far = binF_Far[session][np.arange(len(max_amplitude_Far_idx)), max_amplitude_Far_idx]\n",
    "\n",
    "                # Calculate threshold based on mean and standard deviation of activity values for the session\n",
    "                activity_values = np.concatenate((binF_Near[session][:, :], binF_Far[session][:, :]))\n",
    "                threshold = np.mean(activity_values) + threshold_std * np.std(activity_values)\n",
    "\n",
    "                for j in range(len(max_amplitude_Near)):\n",
    "                    if max_amplitude_Near[j] >= threshold or max_amplitude_Far[j] >= threshold:\n",
    "                        corr_coeff, _ = pearsonr(binF_Near[session][j, :], binF_Far[session][j, :])\n",
    "                        max_amp_ratio = max_amplitude_Near[j] / max_amplitude_Far[j]\n",
    "                        max_amp_diff_score = 1 - min(max_amp_ratio, 1/max_amp_ratio)\n",
    "\n",
    "                        position_Near = max_amplitude_Near_idx[j]\n",
    "                        position_Far = max_amplitude_Far_idx[j]\n",
    "\n",
    "                        # Check if the cell belongs to the current cell type\n",
    "                        for pos_range in cell_type['position']:\n",
    "                            if pos_range[0] <= position_Near < pos_range[1] or pos_range[0] <= position_Far < pos_range[1]:\n",
    "                                corr_coeffs.append(corr_coeff)\n",
    "                                max_amp_diff_scores.append(max_amp_diff_score)\n",
    "                                positions.append((position_Near, position_Far))\n",
    "                                break\n",
    "\n",
    "                # Create heatmap\n",
    "                heatmap, xedges, yedges = np.histogram2d(corr_coeffs, max_amp_diff_scores, bins=50, range=[[-1, 1], [0, 1]], density=True)\n",
    "\n",
    "                # Apply Gaussian smoothing to the heatmap\n",
    "                smoothed_heatmap = gaussian_filter(heatmap, sigma=1)\n",
    "\n",
    "                # Append the smoothed heatmap to the corresponding list\n",
    "                if session == sessions[0]:\n",
    "                    heatmaps_first.append(smoothed_heatmap)\n",
    "                elif session == sessions[len(sessions)//2]:\n",
    "                    heatmaps_middle.append(smoothed_heatmap)\n",
    "                else:\n",
    "                    heatmaps_last.append(smoothed_heatmap)\n",
    "\n",
    "        # Calculate average heatmaps for each session\n",
    "        avg_heatmap_first = np.mean(heatmaps_first, axis=0)\n",
    "        avg_heatmap_middle = np.mean(heatmaps_middle, axis=0)\n",
    "        avg_heatmap_last = np.mean(heatmaps_last, axis=0)\n",
    "\n",
    "        np.savez(data_file, avg_heatmap_first=avg_heatmap_first, avg_heatmap_middle=avg_heatmap_middle, avg_heatmap_last=avg_heatmap_last)\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6), dpi=300)\n",
    "    plt.style.use('default')\n",
    "    cmap = 'viridis'\n",
    "\n",
    "    # Plot the average heatmap for the first session\n",
    "    im1 = ax1.imshow(avg_heatmap_first.T, origin='lower', extent=[-1, 1, 0, 1], cmap=cmap, aspect='auto', vmin=0, vmax=1.5)\n",
    "    ax1.set_xlabel('Correlation', fontsize=20, fontweight='bold')\n",
    "    ax1.set_ylabel('Difference Score', fontsize=20, fontweight='bold')\n",
    "    ax1.set_title(f'{cell_type[\"name\"]} - First Session', fontsize=24, fontweight='bold')\n",
    "    ax1.tick_params(axis='both', labelsize=18, width=2, length=6)\n",
    "    ax1.spines['top'].set_linewidth(1.5)\n",
    "    ax1.spines['right'].set_linewidth(1.5)\n",
    "    ax1.spines['bottom'].set_linewidth(1.5)\n",
    "    ax1.spines['left'].set_linewidth(1.5)\n",
    "\n",
    "    # Plot the average heatmap for the middle session\n",
    "    im2 = ax2.imshow(avg_heatmap_middle.T, origin='lower', extent=[-1, 1, 0, 1], cmap=cmap, aspect='auto', vmin=0, vmax=1.5)\n",
    "    ax2.set_xlabel('Correlation', fontsize=20, fontweight='bold')\n",
    "    ax2.set_title(f'{cell_type[\"name\"]} - Middle Session', fontsize=24, fontweight='bold')\n",
    "    ax2.tick_params(axis='both', labelsize=18, width=2, length=6)\n",
    "    ax2.spines['top'].set_linewidth(1.5)\n",
    "    ax2.spines['right'].set_linewidth(1.5)\n",
    "    ax2.spines['bottom'].set_linewidth(1.5)\n",
    "    ax2.spines['left'].set_linewidth(1.5)\n",
    "\n",
    "    # Plot the average heatmap for the last session\n",
    "    im3 = ax3.imshow(avg_heatmap_last.T, origin='lower', extent=[-1, 1, 0, 1], cmap=cmap, aspect='auto', vmin=0, vmax=1.5)\n",
    "    ax3.set_xlabel('Correlation', fontsize=20, fontweight='bold')\n",
    "    ax3.set_title(f'{cell_type[\"name\"]} - Last Session', fontsize=24, fontweight='bold')\n",
    "    ax3.tick_params(axis='both', labelsize=18, width=2, length=6)\n",
    "    ax3.spines['top'].set_linewidth(1.5)\n",
    "    ax3.spines['right'].set_linewidth(1.5)\n",
    "    ax3.spines['bottom'].set_linewidth(1.5)\n",
    "    ax3.spines['left'].set_linewidth(1.5)\n",
    "\n",
    "    plt.tight_layout(pad=4.0)\n",
    "    plt.savefig(f'plots/heatmaps/all_animals_heatmaps_{cell_type[\"name\"]}_first_middle_last_formatted.pdf', dpi=300, bbox_inches='tight', facecolor='w')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7bc8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the cell types and their corresponding colors\n",
    "cell_types = [\n",
    "    {'name': 'Track Boundary', 'color': 'gray'},\n",
    "    {'name': 'Indicator', 'color': 'orange'},\n",
    "    {'name': 'Intra-Track', 'color': 'mediumturquoise'},\n",
    "]\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 16), dpi=500, sharex=True, sharey=True)\n",
    "\n",
    "for i, cell_type in enumerate(cell_types):\n",
    "    data_file = f'plots/heatmaps/heatmap_data_{cell_type[\"name\"]}.npz'\n",
    "    loaded_data = np.load(data_file)\n",
    "    avg_heatmap_first = loaded_data['avg_heatmap_first']\n",
    "    avg_heatmap_middle = loaded_data['avg_heatmap_middle']\n",
    "    avg_heatmap_last = loaded_data['avg_heatmap_last']\n",
    "\n",
    "    aspect_ratio = 2/(1.1)\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"white\", cell_type['color']])\n",
    "\n",
    "    # Plot the average heatmap for the first session\n",
    "    im1 = axes[i, 0].imshow(avg_heatmap_first.T, origin='lower', extent=[-1, 1, 0, 1], cmap=cmap, vmin=0, vmax=1.5, aspect=aspect_ratio)\n",
    "    axes[i, 0].set_xticks([-1, 0, 1])\n",
    "    axes[i, 0].set_yticks([0, 0.5, 1])\n",
    "\n",
    "    # Plot the average heatmap for the middle session\n",
    "    im2 = axes[i, 1].imshow(avg_heatmap_middle.T, origin='lower', extent=[-1, 1, 0, 1], cmap=cmap, vmin=0, vmax=1.5, aspect=aspect_ratio)\n",
    "    axes[i, 1].set_xticks([-1, 0, 1])\n",
    "    axes[i, 1].set_yticks([0, 0.5, 1])\n",
    "\n",
    "    # Plot the average heatmap for the last session\n",
    "    im3 = axes[i, 2].imshow(avg_heatmap_last.T, origin='lower', extent=[-1, 1, 0, 1], cmap=cmap, vmin=0, vmax=1.5, aspect=aspect_ratio)\n",
    "    axes[i, 2].set_xticks([-1, 0, 1])\n",
    "    axes[i, 2].set_yticks([0, 0.5, 1])\n",
    "\n",
    "# Set x-axis tick labels, font size, and y-axis limits for all subplots\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axes[i, j].set_xticklabels([-1, 0, 1], fontsize=12)\n",
    "        axes[i, j].set_yticklabels([0, 0.5, 1], fontsize=12)\n",
    "        axes[i, j].tick_params(axis='both', labelsize=12, width=2, length=6)\n",
    "        axes[i, j].spines['right'].set_visible(False)\n",
    "        axes[i, j].spines['top'].set_visible(False)\n",
    "        axes[i, j].spines['bottom'].set_visible(True)\n",
    "        axes[i, j].spines['left'].set_visible(True)\n",
    "        axes[i, j].set_ylim(-0.05, 1.05)  # Set y-axis limits from -0.05 to 1.05\n",
    "\n",
    "# Add y-axis labels for the subplots in the first column\n",
    "for i in range(3):\n",
    "    axes[i, 0].set_ylabel('Difference Score', fontsize=14)\n",
    "\n",
    "# Add x-axis labels for the subplots in the last row\n",
    "for j in range(3):\n",
    "    axes[2, j].set_xlabel('Correlation (Near vs Far Trials)', fontsize=14)\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "# Save the main figure as a PDF\n",
    "plt.savefig('Figure_3_FINAL/all_animals_heatmaps_first_middle_last_minimal_seaborn_3by3_square_subplots_revised.pdf', dpi=300, bbox_inches='tight', facecolor='w')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a separate color bar plot\n",
    "fig_cbar, ax_cbar = plt.subplots(figsize=(1, 12), dpi=300)\n",
    "norm = plt.Normalize(vmin=0, vmax=1.5)\n",
    "sm = plt.cm.ScalarMappable(cmap='gray_r', norm=norm)\n",
    "sm.set_array([])  # Dummy array for the ScalarMappable\n",
    "cbar = fig_cbar.colorbar(sm, cax=ax_cbar, orientation='vertical')\n",
    "cbar.set_label('Normalized density', fontsize=40)\n",
    "cbar.ax.tick_params(labelsize=30)  # Increase tick label size\n",
    "cbar.ax.yaxis.set_tick_params(width=2)  # Increase tick size\n",
    "\n",
    "# Save the color bar figure as a PDF\n",
    "plt.savefig('Figure_3_FINAL/colorbar.pdf', dpi=500, bbox_inches='tight', facecolor='w')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
