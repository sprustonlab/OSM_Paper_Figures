{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb5986d2",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad99dac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "import colorcet as cc\n",
    "import pandas as pd\n",
    "from ipyfilechooser import FileChooser\n",
    "from linear2ac.io import get_main_data_folder\n",
    "import zarr\n",
    "import vr2p\n",
    "import vr2p.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde7d921",
   "metadata": {},
   "source": [
    "## Create single trial level tuning matrices for each cell, across all sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14815f91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "animal_name = 'Tyche-A7'\n",
    "\n",
    "data = vr2p.ExperimentData(f'/.../Set A/{animal_name}-SetA.zarr')\n",
    "\n",
    "bin_size = 5\n",
    "min_speed = 5\n",
    "track_size = 230\n",
    "spatial_edges = np.arange(0,track_size + bin_size, bin_size)\n",
    "mid_points = spatial_edges[1:]-(bin_size/2) # mid points of spatial bins.\n",
    "\n",
    "all_fields_N = []\n",
    "all_fields_F = []\n",
    "\n",
    "day_ind_N = []\n",
    "day_ind_F = []\n",
    "\n",
    "for session in range(len(data.vr)):\n",
    "    print(f'On Session {session}')\n",
    "    vr = data.vr[session]\n",
    "    trial = vr.trial.copy()\n",
    "    position = vr.path.frame.copy().reset_index()\n",
    "    # merge reward_id info\n",
    "    position = position.merge(trial[['trial_number','reward_id']],on='trial_number')\n",
    "    F = data.signals.multi_session.Fdemix[int(session)]\n",
    "    F = F[:]\n",
    "    F =  F-np.min(F,axis=1)[..., np.newaxis]\n",
    "    # calculate df (Based on all frames.)\n",
    "    dF_F0, _ = vr2p.signal.df_over_f0(F,'maximin',subtract_min=True,\n",
    "        sigma_baseline=20, window_size = 200)\n",
    "\n",
    "    for reward_id in [1,2]:\n",
    "        #print(f'  On reward_id {reward_id}')\n",
    "\n",
    "        \n",
    "        selected_trials = trial.loc[(trial.reward_id == reward_id),'trial_number']\n",
    "        selected_frames = position.loc[position['trial_number'].isin(selected_trials),'frame']\n",
    "        position['speed'] = position.vr2p.rolling_speed(\n",
    "            window_size = 100, ignore_threshold = 7.5)\n",
    "        # filter frames with min speed and in 'selected_frames'\n",
    "        filtered_frames = position.loc[(position['speed']>=min_speed) & position['frame'].isin(selected_frames),'frame']\n",
    "        filtered_pos_data = position.loc[position['frame'].isin(filtered_frames),['frame','position','trial_number']]\n",
    "\n",
    "\n",
    "        for trial_n in selected_trials:\n",
    "            #print(f'On trial {trial_n}')\n",
    "\n",
    "\n",
    "            single_pos_data = filtered_pos_data[filtered_pos_data.trial_number==trial_n]\n",
    "        \n",
    "            if len(single_pos_data.position) == 0 or (len(single_pos_data.position) > 0 and np.nanmax(single_pos_data.position) < 226):\n",
    "  \n",
    "                #print(f'    skipping incomplete trial {trial_n}')\n",
    "                continue \n",
    "            bin_pos = single_pos_data.copy()\n",
    "            # change trials to rank order (for filling out matrix).\n",
    "            bin_pos['trial_number'] = (bin_pos['trial_number'].rank(method='dense')-1).astype(int)\n",
    "\n",
    "            # Assign bin position.\n",
    "            bin_pos['bin'] = pd.cut(bin_pos.position,spatial_edges, include_lowest=True,labels=False).to_numpy().astype(int)\n",
    "            bin_pos = bin_pos.loc[bin_pos.bin>=0] # valid bins only.\n",
    "            # prepare binF matrix.\n",
    "            num_trials = bin_pos.trial_number.max()+1\n",
    "            num_bins = spatial_edges.size-1\n",
    "            num_cells = F.shape[0]\n",
    "            if np.isnan(num_trials): num_trials=0\n",
    "            binF_mat = np.full((num_trials,num_bins,num_cells),np.nan) # holds mean fluorescence data.\n",
    "            # Get frames per trial and bin.\n",
    "            bin_pos = bin_pos.groupby(['trial_number','bin']).agg({'frame':list})\n",
    "            # get mean dF value for each bin, trial frame set.\n",
    "            for index, row in bin_pos.iterrows():\n",
    "                binF_mat[index[0],index[1],:] = np.mean(dF_F0[:,row['frame']],axis=1)\n",
    "\n",
    "            binF_mat = np.swapaxes(binF_mat, 1, 2)\n",
    "            \n",
    "            \n",
    "            if reward_id == 1:\n",
    "                all_fields_N.append(binF_mat)\n",
    "                day_ind_N.append(session)\n",
    "            if reward_id == 2:\n",
    "                all_fields_F.append(binF_mat)\n",
    "                day_ind_F.append(session)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8644575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "new_all_N = np.squeeze(np.array(all_fields_N))\n",
    "array_2d_N = new_all_N.reshape(-1, 46)\n",
    "\n",
    "new_all_F = np.squeeze(np.array(all_fields_F))\n",
    "array_2d_F = new_all_F.reshape(-1, 46)\n",
    "\n",
    "\n",
    "# Create the SimpleImputer and specify the imputation strategy\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Fit the imputer and transform the data to remove nan values. \n",
    "imputed_array_2d_N = imputer.fit_transform(array_2d_N)\n",
    "imputed_array_2d_F = imputer.fit_transform(array_2d_F)\n",
    "\n",
    "\n",
    "# Reshape the imputed 2D array back to 3D\n",
    "imputed_array_3d_N = imputed_array_2d_N.reshape(*new_all_N.shape)\n",
    "imputed_array_3d_F = imputed_array_2d_F.reshape(*new_all_F.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7170cbe",
   "metadata": {},
   "source": [
    "## Quantify spatial dispersion by entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "    \n",
    "def single_centers(session_data):\n",
    "    '''function taking in place field object and output the \n",
    "       center of the strongest place field for each cell'''\n",
    "\n",
    "    props = regionprops(session_data['label_im'],session_data['binF'], cache=False)\n",
    "    mean_intensity = np.array([prop[\"mean_intensity\"]for prop in props])\n",
    "\n",
    "    num_cells = session_data['binF'].shape[0]\n",
    "    single_centers = np.full(num_cells,np.inf)\n",
    "    intensity = mean_intensity\n",
    "\n",
    "    cell_id = session_data['centers'][:,0].astype(int)\n",
    "    # in case a cell has two place fields, order on one with highest mean intensity.\n",
    "    for icell in range(num_cells):\n",
    "        cell_ind = np.argwhere(cell_id==icell)\n",
    "        if cell_ind.size>0:\n",
    "            ind = np.argmax(intensity[cell_id==icell])\n",
    "            single_centers[icell] = session_data['centers'][cell_ind[ind],1]\n",
    "    return single_centers\n",
    "\n",
    "## Function for finding gray-zone-coding cells:\n",
    "def gray_region_cell_ind(gray_regions,selected_sessions,trial_types):\n",
    "\n",
    "    gray_region_ind = set()\n",
    "\n",
    "    for session_n in selected_sessions:\n",
    "        indices = []\n",
    "        \n",
    "        for trial_n in range(len(trial_types)):\n",
    "            \n",
    "            trial_type = trial_types[trial_n]\n",
    "            \n",
    "            centers = single_centers(trial_type[session_n]) / 5  # Get center positions for each cell\n",
    "\n",
    "            for idx, center in enumerate(centers):\n",
    "                # Ignore cells with np.inf center value\n",
    "                if center == np.inf:\n",
    "                    continue\n",
    "\n",
    "                # Check if the center is in any of the gray regions\n",
    "                center_in_gray_region = any([int(center) in gray_region for gray_region in gray_regions])\n",
    "\n",
    "                if center_in_gray_region:\n",
    "                    indices.append(idx)  # Add the index of the cell with the center in a gray region\n",
    "            # Update the total set\n",
    "            print(f\"Function output: Session {session_n}, total: {len(gray_region_ind)} cells\")\n",
    "        gray_region_ind.update(set(indices))\n",
    "    return np.array(list(gray_region_ind))\n",
    "\n",
    "def pos_entropy(signal: np.ndarray) -> float:\n",
    "    \n",
    "    signal[signal<0] = 0\n",
    "    # Normalize the signal to have a sum of 1, so that it acts like a probability distribution\n",
    "    normalized_signal = signal / np.sum(signal)\n",
    "\n",
    "    # Calculate the entropy of the normalized signal\n",
    "    entropy = -np.sum(normalized_signal * np.log2(normalized_signal + np.finfo(float).eps))\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_regions = [np.arange(0, 12), np.arange(20, 26), np.arange(30, 36), np.arange(40, 46)]\n",
    "selected_sessions = [0,1,2]\n",
    "trial_types = [pf_all_T1] ## analyzing only near trials for now\n",
    "\n",
    "gray_region_ind = gray_region_cell_ind(gray_regions,selected_sessions,trial_types)\n",
    "\n",
    "# take all animals date plot day 0 and day 2 entropy\n",
    "entropy_1 = []\n",
    "entropy_2 = []\n",
    "\n",
    "cell_array = gray_region_ind\n",
    "\n",
    "\n",
    "for i in cell_array:\n",
    "    aa = imputed_array_3d_N[np.isin(np.array(day_ind_N), [0,1,2]),i,:]\n",
    "    entropy_1.append(pos_entropy(np.mean(aa[0:60,:],0)))\n",
    "    entropy_2.append(pos_entropy(np.mean(aa[60:,:],0)))\n",
    "    \n",
    "entropy_1 = np.array(entropy_1)\n",
    "entropy_2 = np.array(entropy_2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_change = cell_array[np.argsort(entropy_1 - entropy_2)[-200:]]\n",
    "high_change_neg = cell_array[np.argsort(entropy_1 - entropy_2)[0:40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7352fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(3, 3), dpi=100)\n",
    "\n",
    "# Compute the entropy range and bin edges\n",
    "entropy_min = 0\n",
    "entropy_max = 10\n",
    "nbins = 100\n",
    "bin_edges = np.linspace(entropy_min, entropy_max, num= nbins + 1)\n",
    "\n",
    "# Compute the binned entropy histograms for each session\n",
    "hist_1, _ = np.histogram(entropy_1, bins=bin_edges)\n",
    "hist_2, _ = np.histogram(entropy_2, bins=bin_edges)\n",
    "\n",
    "# Compute the cumulative percentages for each bin\n",
    "cumulative_percentage_1 = np.cumsum(hist_1) / len(entropy_1) * 100\n",
    "cumulative_percentage_2 = np.cumsum(hist_2) / len(entropy_2) * 100\n",
    "\n",
    "# Plot the cumulative percentages on the subplot\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "axs.plot(bin_centers, cumulative_percentage_1, color='blue', label='Session 0')\n",
    "axs.plot(bin_centers, cumulative_percentage_2, color='orange', label='Session 2')\n",
    "\n",
    "# Add labels and title to the subplot\n",
    "axs.set_xlabel('Entropy values')\n",
    "axs.set_ylabel('Cumulative percentage of cells')\n",
    "axs.set_xlim([3, 6])\n",
    "axs.set_ylim([0, 100])\n",
    "\n",
    "# Add a legend to the plot\n",
    "axs.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7155d36a",
   "metadata": {},
   "source": [
    "## Visualize place fields over trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8925836",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cell_array = gray_region_ind\n",
    "\n",
    "cell_array = high_change ## selecting high entropy decrease cells\n",
    "\n",
    "# Determine the number of rows and columns for the subplots\n",
    "num_cols = 15\n",
    "num_rows = int(np.ceil(len(cell_array) / num_cols ))\n",
    "\n",
    "#vmax = np.nanmax(imputed_array_3d_N[np.isin(np.array(day_ind_N), [0,1,2]),index,:]) / 2\n",
    "\n",
    "vmax = 4.5\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(40, 4*num_rows), dpi=300)\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < len(cell_array):\n",
    "        index = cell_array[i]\n",
    "        im = ax.imshow(imputed_array_3d_N[np.isin(np.array(day_ind_N), [0,1,2]),index,:], aspect='auto', cmap='jet', vmin=0, vmax=vmax, interpolation=None)\n",
    "        ax.set_title(f\"Cell {index}\")\n",
    "        fig.colorbar(im, ax=ax)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bffbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Functions for using strongest place field's center postion to check if a cell is coding for the \"Gray zones\"\n",
    "\n",
    "from skimage.measure import regionprops\n",
    "    \n",
    "def single_centers(session_data):\n",
    "    '''function taking in place field object and output the \n",
    "       center of the strongest place field for each cell'''\n",
    "\n",
    "    props = regionprops(session_data['label_im'],session_data['binF'], cache=False)\n",
    "    mean_intensity = np.array([prop[\"mean_intensity\"]for prop in props])\n",
    "\n",
    "    num_cells = session_data['binF'].shape[0]\n",
    "    single_centers = np.full(num_cells,np.inf)\n",
    "    intensity = mean_intensity\n",
    "\n",
    "    cell_id = session_data['centers'][:,0].astype(int)\n",
    "    # in case a cell has two place fields, order on one with highest mean intensity.\n",
    "    for icell in range(num_cells):\n",
    "        cell_ind = np.argwhere(cell_id==icell)\n",
    "        if cell_ind.size>0:\n",
    "            ind = np.argmax(intensity[cell_id==icell])\n",
    "            single_centers[icell] = session_data['centers'][cell_ind[ind],1]\n",
    "    return single_centers\n",
    "\n",
    "## Function for finding gray-zone-coding cells:\n",
    "def gray_region_cell_ind(gray_regions,selected_sessions,trial_types):\n",
    "\n",
    "    gray_region_ind = set()\n",
    "\n",
    "    for session_n in selected_sessions:\n",
    "        indices = []\n",
    "        \n",
    "        for trial_n in range(len(trial_types)):\n",
    "            \n",
    "            trial_type = trial_types[trial_n]\n",
    "            \n",
    "            centers = single_centers(trial_type[session_n]) / 5  # Get center positions for each cell\n",
    "\n",
    "            for idx, center in enumerate(centers):\n",
    "                # Ignore cells with np.inf center value\n",
    "                if center == np.inf:\n",
    "                    continue\n",
    "\n",
    "                # Check if the center is in any of the gray regions\n",
    "                center_in_gray_region = any([int(center) in gray_region for gray_region in gray_regions])\n",
    "\n",
    "                if center_in_gray_region:\n",
    "                    indices.append(idx)  # Add the index of the cell with the center in a gray region\n",
    "            # Update the total set\n",
    "            print(f\"Function output: Session {session_n}, total: {len(gray_region_ind)} cells\")\n",
    "            gray_region_ind.update(set(indices))\n",
    "    return np.array(list(gray_region_ind))\n",
    "\n",
    "def pos_entropy(signal: np.ndarray) -> float:\n",
    "    \n",
    "    signal[signal<0] = 0\n",
    "    # Normalize the signal to have a sum of 1, so that it acts like a probability distribution\n",
    "    normalized_signal = signal / np.sum(signal)\n",
    "\n",
    "    # Calculate the entropy of the normalized signal\n",
    "    entropy = -np.sum(normalized_signal * np.log2(normalized_signal + np.finfo(float).eps))\n",
    "\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d3bc5b",
   "metadata": {},
   "source": [
    "## Analyze spatial dispersion for all animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe99d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "anm = os.listdir('/.../Set A/')\n",
    "animal_list = [name[0:8] for name in anm]\n",
    "animal_list = animal_list[1:] ## removing .DS_Stor file\n",
    "\n",
    "gray_regions = [np.arange(0, 12), np.arange(20, 26), np.arange(30, 36), np.arange(40, 46)]\n",
    "\n",
    "selected_sessions = [0,1,2]\n",
    "\n",
    "all_anm_entropy_s0 = []\n",
    "all_anm_entropy_s2 = []\n",
    "\n",
    "for animal_name in animal_list:\n",
    "    print(animal_name)\n",
    "    \n",
    "    #load stored place field analysis for each day\n",
    "    zarr_file = zarr.open(f'/nrs/spruston/Tyche/vr2p_datasets/placefields/50_600_SetA/{animal_name}-PF.zarr', mode=\"r\")\n",
    "    \n",
    "    num_A_days = len(zarr_file[f'Cue Set A/1/excl_no_response/'])\n",
    "    \n",
    "    range_A = range(num_A_days)\n",
    "    criteria = 'putative'\n",
    "    \n",
    "    pf_all_T1 = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "    pf_all_T2 = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "\n",
    "    binF_T1 = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "    binF_T2 = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "\n",
    "    binF_T1_all = np.array(binF_T1).T\n",
    "    binF_T2_all = np.array(binF_T2).T\n",
    "    \n",
    "    \n",
    "    # find gray indices for session 0,1,2\n",
    "    trial_types = [pf_all_T1] ## analyzing only near trials for now\n",
    "    gray_region_ind = gray_region_cell_ind(gray_regions,selected_sessions,trial_types)\n",
    "\n",
    "    # take all animals date plot day 0 and day 2 entropy\n",
    "    entropy_session_0 = []\n",
    "    entropy_session_2 = []\n",
    "\n",
    "    cell_array = gray_region_ind\n",
    "    \n",
    "    for cell_ind in cell_array:\n",
    "\n",
    "        entropy_session_0.append(pos_entropy(binF_T1_all[:,cell_ind,0]))\n",
    "        entropy_session_2.append(pos_entropy(binF_T1_all[:,cell_ind,2]))\n",
    "\n",
    "    all_anm_entropy_s0.append(entropy_session_0)\n",
    "    all_anm_entropy_s2.append(entropy_session_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473c828",
   "metadata": {},
   "source": [
    "## Plotting entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the entropy range and bin edges\n",
    "entropy_min = 0\n",
    "entropy_max = 10\n",
    "nbins = 100\n",
    "bin_edges = np.linspace(entropy_min, entropy_max, num= nbins + 1)\n",
    "\n",
    "cumulative_fraction_s0 = []\n",
    "cumulative_fraction_s2 = []\n",
    "\n",
    "for entropy in all_anm_entropy_s0:\n",
    "    \n",
    "    hist, _ = np.histogram(entropy, bins=bin_edges)\n",
    "    cumulative_fraction = np.cumsum(hist) / len(entropy) \n",
    "    cumulative_fraction_s0.append(cumulative_fraction)\n",
    "    \n",
    "cumulative_fraction_s2 = []\n",
    "for entropy in all_anm_entropy_s2:\n",
    "    \n",
    "    hist, _ = np.histogram(entropy, bins=bin_edges)\n",
    "    cumulative_fraction = np.cumsum(hist) / len(entropy) \n",
    "    cumulative_fraction_s2.append(cumulative_fraction)\n",
    "    \n",
    "cumulative_fraction_s0 = np.array(cumulative_fraction_s0)\n",
    "cumulative_fraction_s2 = np.array(cumulative_fraction_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ce70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the mean and standard error of the mean for each array along the 0th dimension\n",
    "mean_s0 = np.mean(cumulative_fraction_s0, axis=0)\n",
    "sem_s0 = np.std(cumulative_fraction_s0, axis=0) / np.sqrt(cumulative_fraction_s0.shape[0])\n",
    "mean_s2 = np.mean(cumulative_fraction_s2, axis=0)\n",
    "sem_s2 = np.std(cumulative_fraction_s2, axis=0) / np.sqrt(cumulative_fraction_s2.shape[0])\n",
    "\n",
    "# Set up the plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(5, 5), dpi=600)\n",
    "\n",
    "# Plot the means with shaded error bars\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "axs.plot(bin_centers, mean_s0, color='black', label='Day 0')\n",
    "axs.fill_between(bin_centers, mean_s0 - sem_s0, mean_s0 + sem_s0, alpha=0.2, color='black')\n",
    "axs.plot(bin_centers, mean_s2, color='purple', label='Day 1')\n",
    "axs.fill_between(bin_centers, mean_s2 - sem_s2, mean_s2 + sem_s2, alpha=0.2, color='purple')\n",
    "\n",
    "# Add labels and title to the subplot\n",
    "axs.set_xlabel('Spatial dispersion index', fontsize=18)\n",
    "axs.set_ylabel('Cumulative fraction', fontsize=18)\n",
    "axs.set_xlim([2, 6])\n",
    "axs.set_ylim([0, 1.05])\n",
    "axs.tick_params(labelsize=15)\n",
    "\n",
    "# Add a legend to the plot\n",
    "axs.legend(fontsize=15)\n",
    "\n",
    "# Save the plot as a PDF with dpi=500\n",
    "plt.savefig('spatial_dispersion.pdf', format='pdf', dpi=500)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6bbd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the arrays\n",
    "all_anm_entropy_s0_flat = np.concatenate(all_anm_entropy_s0)\n",
    "all_anm_entropy_s2_flat= np.concatenate(all_anm_entropy_s2)\n",
    "\n",
    "# Remove any NaN values\n",
    "all_anm_entropy_s0_flat  = all_anm_entropy_s0_flat [~np.isnan(all_anm_entropy_s0_flat )]\n",
    "all_anm_entropy_s2_flat = all_anm_entropy_s2_flat[~np.isnan(all_anm_entropy_s2_flat)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Mann-Whitney U test\n",
    "U, p_value = stats.mannwhitneyu(all_anm_entropy_s0_flat, all_anm_entropy_s2_flat, alternative='two-sided')\n",
    "\n",
    "# Print the result\n",
    "print(\"Mann-Whitney U statistic:\", U)\n",
    "\n",
    "if p_value == 0:\n",
    "    print(\"p-value is less than the precision of Python's floating-point arithmetic (typically around 1e-16 to 1e-308).\")\n",
    "else:\n",
    "    print(\"p-value:\", p_value)\n",
    "\n",
    "print(\"The Mann-Whitney U test showed a statistically significant difference between the two groups (U = 302559180.0, p < 0.000001)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Wilcoxon rank-sum test\n",
    "W, p_value = stats.ranksums(all_anm_entropy_s0_flat, all_anm_entropy_s2_flat)\n",
    "\n",
    "# Print the result\n",
    "print(\"Wilcoxon rank-sum statistic:\", W)\n",
    "\n",
    "if p_value == 0:\n",
    "    print(\"p-value is less than the precision of Python's floating-point arithmetic (typically around 1e-16 to 1e-308).\")\n",
    "else:\n",
    "    print(\"p-value:\", p_value)\n",
    "\n",
    "print(\"The Wilcoxon rank-sum test showed a statistically significant difference between the two groups (W = {}, p < 0.000001)\".format(W))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bf4145",
   "metadata": {},
   "source": [
    "## Stage 2 to 3 transition: Pre-R2 - R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649eebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pre_R2_region_cell_ind(Pre_R2_region,selected_sessions,trial_types):\n",
    "\n",
    "    Pre_R2_region_ind = set()\n",
    "\n",
    "    for session_n in selected_sessions:\n",
    "        indices = []\n",
    "        \n",
    "        for trial_n in range(len(trial_types)):\n",
    "            \n",
    "            trial_type = trial_types[trial_n]\n",
    "            \n",
    "            centers = single_centers(trial_type[session_n]) / 5  # Get center positions for each cell\n",
    "\n",
    "            for idx, center in enumerate(centers):\n",
    "                # Ignore cells with np.inf center value\n",
    "                if center == np.inf:\n",
    "                    continue\n",
    "                center_in_region = any([int(center) in Pre_R2_region])\n",
    "\n",
    "                if center_in_region:\n",
    "                    indices.append(idx)  \n",
    "            # Update the total set\n",
    "            print(f\"Function output: Session {session_n}, total: {len(Pre_R2_region_ind)} cells\")\n",
    "            Pre_R2_region_ind.update(set(indices))\n",
    "    return np.array(list(Pre_R2_region_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f537d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for all animals, for each, find significant cell field centers within the range. \n",
    "\n",
    "import os\n",
    "anm = os.listdir('/.../Set A/')\n",
    "animal_list = [name[0:8] for name in anm]\n",
    "animal_list = animal_list[1:] ## removing .DS_Stor\n",
    "\n",
    "# Define Region \n",
    "Pre_R2_region = np.arange(34, 37)\n",
    "\n",
    "all_anm_Pre_R2_diff = []\n",
    "Pre_R2_region_ind_all = []\n",
    "\n",
    "for animal_name in animal_list:\n",
    "    print(animal_name)\n",
    "    #load stored place field analysis for each day\n",
    "    zarr_file = zarr.open(f'/SetA/{animal_name}-PF.zarr', mode=\"r\")\n",
    "\n",
    "    num_A_days = len(zarr_file[f'Cue Set A/1/excl_no_response/'])\n",
    "\n",
    "    range_A = range(num_A_days)\n",
    "    criteria = 'significant'\n",
    "\n",
    "    pf_all_T1 = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "    pf_all_T2 = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "\n",
    "    binF_T1 = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "    binF_T2 = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "\n",
    "    binF_T1_all = np.array(binF_T1).T\n",
    "    binF_T2_all = np.array(binF_T2).T\n",
    "\n",
    "    selected_sessions = range_A\n",
    "\n",
    "    trial_types = [pf_all_T1,pf_all_T2] ## analyzing only near trials for now\n",
    "\n",
    "    Pre_R2_region_ind = Pre_R2_region_cell_ind(Pre_R2_region,selected_sessions,trial_types)\n",
    "    Pre_R2_region_ind_all.append(Pre_R2_region_ind)\n",
    "    anm_diff = []\n",
    "    for session_n in range_A:\n",
    "        diff = np.mean(binF_T1_all[:,Pre_R2_region_ind ,session_n][Pre_R2_region,:],0) \\\n",
    "            - np.mean(binF_T2_all[:,Pre_R2_region_ind ,session_n][Pre_R2_region,:],0)\n",
    "        anm_diff.append(diff)\n",
    "    all_anm_Pre_R2_diff.append(anm_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2c3f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diff_min = 0\n",
    "diff_max = 6\n",
    "nbins = 100\n",
    "bin_edges = np.linspace(diff_min, diff_max, num= nbins + 1)\n",
    "\n",
    "cumulative_fraction_all_s0 = []\n",
    "animal_diff_all_s0 = []\n",
    "for diff in all_anm_Pre_R2_diff:\n",
    "    anm_diff = np.abs(np.array(diff)[0,:])\n",
    "    animal_diff_all_s0.append(anm_diff)    \n",
    "    hist, _ = np.histogram(anm_diff, bins=bin_edges)\n",
    "    cumulative_fraction = np.cumsum(hist) / len(anm_diff) \n",
    "    cumulative_fraction_all_s0.append(cumulative_fraction)\n",
    "    \n",
    "    \n",
    "    \n",
    "cumulative_fraction_all_s_end = []\n",
    "animal_diff_all_end = []\n",
    "\n",
    "for diff in all_anm_Pre_R2_diff:\n",
    "    anm_diff = np.abs(np.array(diff)[-1,:])\n",
    "    animal_diff_all_end.append(anm_diff)    \n",
    "    hist, _ = np.histogram(anm_diff, bins=bin_edges)\n",
    "    cumulative_fraction = np.cumsum(hist) / len(anm_diff) \n",
    "    cumulative_fraction_all_s_end.append(cumulative_fraction)\n",
    "    \n",
    "    \n",
    "cumulative_fraction_all_s0 = np.array(cumulative_fraction_all_s0)\n",
    "cumulative_fraction_all_s_end = np.array(cumulative_fraction_all_s_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fe66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the arrays\n",
    "animal_diff_all_s0_flat = np.concatenate(animal_diff_all_s0)\n",
    "animal_diff_all_end_flat= np.concatenate(animal_diff_all_end)\n",
    "\n",
    "# Remove any NaN values\n",
    "animal_diff_all_s0_flat = animal_diff_all_s0_flat [~np.isnan(animal_diff_all_s0_flat)]\n",
    "animal_diff_all_end_flat = animal_diff_all_end_flat[~np.isnan(animal_diff_all_end_flat)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea7263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard error of the mean for each array\n",
    "mean_s0 = np.mean(cumulative_fraction_all_s0, axis=0)\n",
    "sem_s0 = np.std(cumulative_fraction_all_s0, axis=0) / np.sqrt(cumulative_fraction_all_s0.shape[0])\n",
    "mean_s_end = np.mean(cumulative_fraction_all_s_end, axis=0)\n",
    "sem_s_end = np.std(cumulative_fraction_all_s_end, axis=0) / np.sqrt(cumulative_fraction_all_s_end.shape[0])\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(5, 5), dpi=600)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "axs.plot(bin_centers, mean_s0, color='black', label='Session 1')\n",
    "axs.fill_between(bin_centers, mean_s0 - sem_s0, mean_s0 + sem_s0, alpha=0.2, color='black')\n",
    "axs.plot(bin_centers, mean_s_end, color='purple', label='Last session')\n",
    "axs.fill_between(bin_centers, mean_s_end - sem_s_end, mean_s_end + sem_s_end, alpha=0.2, color='purple')\n",
    "axs.set_xlabel('dF/F difference in Pre-R2', fontsize=18)\n",
    "axs.set_ylabel('Cumulative fraction', fontsize=18)\n",
    "axs.set_xlim([0, 3])\n",
    "axs.set_ylim([0, 1.05])\n",
    "axs.tick_params(labelsize=15)\n",
    "axs.legend(fontsize=15)\n",
    "plt.savefig('stage_2_to_3.pdf', format='pdf', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ebe656",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(animal_diff_all_end_flat)\n",
    "plt.plot(animal_diff_all_s0_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a379a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W, p_value_W = stats.ranksums(animal_diff_all_s0_flat, animal_diff_all_end_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255112c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "U, p_value_U = stats.mannwhitneyu(animal_diff_all_s0_flat, animal_diff_all_end_flat, alternative='two-sided')\n",
    "\n",
    "# Print the Mann-Whitney U result\n",
    "print(\"Mann-Whitney U statistic:\", U)\n",
    "print(\"Mann-Whitney U p-value:\", p_value_U)\n",
    "if p_value_U == 0:\n",
    "    print(\"Mann-Whitney U p-value is less than the precision of Python's floating-point arithmetic (typically around 1e-16 to 1e-308).\")\n",
    "else:\n",
    "    print(\"Mann-Whitney U p-value:\", p_value_U)\n",
    "\n",
    "# Perform the Wilcoxon Rank Sum test\n",
    "W, p_value_W = stats.ranksums(animal_diff_all_s0_flat, animal_diff_all_end_flat)\n",
    "\n",
    "# Print the Wilcoxon Rank Sum result\n",
    "print(\"Wilcoxon Rank Sum statistic:\", W)\n",
    "print(\"Wilcoxon Rank Sum p-value:\", p_value_W)\n",
    "if p_value_W == 0:\n",
    "    print(\"Wilcoxon Rank Sum p-value is less than the precision of Python's floating-point arithmetic (typically around 1e-16 to 1e-308).\")\n",
    "else:\n",
    "    print(\"Wilcoxon Rank Sum p-value:\", p_value_W)\n",
    "\n",
    "# Print statement about statistical significance \n",
    "print(\"If the p-value is less than 0.05, the Wilcoxon rank-sum test shows a statistically significant difference between the two groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5835cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ind = Pre_R2_region_ind_all[2][np.argsort(np.abs(all_anm_Pre_R2_diff[2][-1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41535b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load stored place field analysis for each day\n",
    "zarr_file = zarr.open(f'/.../SetA/Tyche-A7-PF.zarr', mode=\"r\")\n",
    "\n",
    "num_A_days = len(zarr_file[f'Cue Set A/1/excl_no_response/'])\n",
    "\n",
    "range_A = range(num_A_days)\n",
    "criteria = 'putative'\n",
    "\n",
    "pf_all_T1 = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "pf_all_T2 = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "\n",
    "binF_T1 = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "binF_T2 = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "\n",
    "binF_T1_all = np.array(binF_T1).T\n",
    "binF_T2_all = np.array(binF_T2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc1fd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cell_array = sorted_ind[-400:]\n",
    "session_range = np.arange(9)\n",
    "# Determine the number of rows and columns for the subplots\n",
    "num_cols = 10\n",
    "num_rows = int(np.ceil(len(cell_array) / num_cols ))\n",
    "\n",
    "x_start = 34\n",
    "x_end = 37\n",
    "vmax = 4\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(30, 4*num_rows), dpi=300)\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < len(cell_array):\n",
    "        index = cell_array[i]\n",
    "        stacked_Near_Far = np.hstack((binF_T1_all[:,index,:],binF_T2_all[:,index,:])).T\n",
    "        im = ax.imshow(stacked_Near_Far, aspect='auto', cmap='jet', vmin=0, vmax=vmax, interpolation=None)\n",
    "        ax.set_title(f\"Cell {index}\")\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        ax.axvline(x=x_start, linestyle='--', color='white', linewidth=1)\n",
    "        ax.axvline(x=x_end, linestyle='--', color='white', linewidth=1)\n",
    "        ax.axhline(y=9, linestyle='--', color='white', linewidth=1)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aba25d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cell_num = [3312,5203]\n",
    "\n",
    "x_start = 34*5\n",
    "x_end = 37*5\n",
    "\n",
    "vmin = 0\n",
    "vmax = 4\n",
    "region_marker_opacity = 0.1\n",
    "dpi = 600\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(4,6), dpi=dpi, facecolor='white', sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    q,r = divmod(i, 2) \n",
    "    # plot heatmap.\n",
    "    if r == 0:\n",
    "        x_extent = (0, 230,binF_T1_all[:,cell_num[q],:].T.shape[0],0)\n",
    "        h = ax.imshow(binF_T1_all[:,cell_num[q],:].T, aspect='auto', cmap='jet', vmin=vmin, vmax=vmax, interpolation=None, extent=x_extent)\n",
    "        ax.set_title(f'Cell {cell_num[q]}', fontsize=12)\n",
    "    if r == 1:\n",
    "        x_extent = (0, 230,binF_T2_all[:,cell_num[q],:].T.shape[0],0)\n",
    "        h = ax.imshow(binF_T2_all[:,cell_num[q],:].T, aspect='auto', cmap='jet', vmin=vmin, vmax=vmax, interpolation=None, extent=x_extent)\n",
    "        ax.set_title(f'Cell {cell_num[q]}', fontsize=12)\n",
    "\n",
    "    print(i)\n",
    "    if i >= 2:\n",
    "        ax.set_xlabel('Position (cm)', fontsize=12)\n",
    "    if i % 2 == 0:\n",
    "        ax.set_ylabel('Session number', fontsize=12)\n",
    "        y_ticks = np.arange(0.5, 9.5)\n",
    "        ylabels = [str(i) for i in range(1, 10)]  \n",
    "\n",
    "        ax.set_yticks(y_ticks)\n",
    "        ax.set_yticklabels(ylabels)\n",
    "        \n",
    "    else:\n",
    "        ax.set_ylabel('', fontsize=12)\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    #ax.set_title(f'Cell {cell_num[i]}', fontsize=12)\n",
    "#     ax.axvline(x=x_start, linestyle='--', color='white', linewidth=1)\n",
    "#     ax.axvline(x=x_end, linestyle='--', color='white', linewidth=1)\n",
    "\n",
    "# colorbar.\n",
    "cbar = fig.colorbar(h, ax=axs.ravel().tolist(), label='dF/F0')\n",
    "cbar.ax.set_position([0.99, 0.1, 0.02, 0.8])\n",
    "cbar.ax.set_ylabel('dF/F0', fontsize=12)\n",
    "cbar.ax.yaxis.set_tick_params(labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Example_stage_2_3_cells.pdf', format='pdf', dpi=500) # This line saves the plot as a pdf with dpi = 500\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2e267",
   "metadata": {},
   "source": [
    "## Stage 2 to 3 transition: Pre-R1 - R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867967b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pre_R1_region_cell_ind(Pre_R1_region,selected_sessions,trial_types):\n",
    "\n",
    "    Pre_R1_region_ind = set()\n",
    "\n",
    "    for session_n in selected_sessions:\n",
    "        indices = []\n",
    "        \n",
    "        for trial_n in range(len(trial_types)):\n",
    "            \n",
    "            trial_type = trial_types[trial_n]\n",
    "            \n",
    "            centers = single_centers(trial_type[session_n]) / 5  # Get center positions for each cell\n",
    "\n",
    "            for idx, center in enumerate(centers):\n",
    "                # Ignore cells with np.inf center value\n",
    "                if center == np.inf:\n",
    "                    continue\n",
    "                center_in_region = any([int(center) in Pre_R1_region])\n",
    "\n",
    "                if center_in_region:\n",
    "                    indices.append(idx)  \n",
    "            # Update the total set\n",
    "            print(f\"Function output: Session {session_n}, total: {len(Pre_R1_region_ind)} cells\")\n",
    "            Pre_R1_region_ind.update(set(indices))\n",
    "    return np.array(list(Pre_R1_region_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22348a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for all animals, for each, find significant cell field centers within the range. \n",
    "\n",
    "import os\n",
    "anm = os.listdir('/.../Set A/')\n",
    "animal_list = [name[0:8] for name in anm]\n",
    "animal_list = animal_list[1:] ## removing .DS_Stor\n",
    "\n",
    "# Define Region \n",
    "Pre_R1_region = np.arange(24, 27)\n",
    "\n",
    "all_anm_Pre_R1_diff = []\n",
    "Pre_R1_region_ind_all = []\n",
    "\n",
    "for animal_name in animal_list:\n",
    "    print(animal_name)\n",
    "    #load stored place field analysis for each day\n",
    "    zarr_file = zarr.open(f'/SetA/{animal_name}-PF.zarr', mode=\"r\")\n",
    "\n",
    "    num_A_days = len(zarr_file[f'Cue Set A/1/excl_no_response/'])\n",
    "\n",
    "    range_A = range(num_A_days)\n",
    "    criteria = 'putative'\n",
    "\n",
    "    pf_all_T1 = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "    pf_all_T2 = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "\n",
    "    binF_T1 = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "    binF_T2 = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "\n",
    "    binF_T1_all = np.array(binF_T1).T\n",
    "    binF_T2_all = np.array(binF_T2).T\n",
    "\n",
    "    selected_sessions = range_A\n",
    "\n",
    "    trial_types = [pf_all_T1,pf_all_T2] \n",
    "\n",
    "    Pre_R1_region_ind = Pre_R1_region_cell_ind(Pre_R1_region,selected_sessions,trial_types)\n",
    "    Pre_R1_region_ind_all.append(Pre_R1_region_ind)\n",
    "    anm_diff = []\n",
    "    for session_n in range_A:\n",
    "        diff = np.mean(binF_T1_all[:,Pre_R1_region_ind ,session_n][Pre_R1_region,:],0) \\\n",
    "            - np.mean(binF_T2_all[:,Pre_R1_region_ind ,session_n][Pre_R1_region,:],0)\n",
    "        anm_diff.append(diff)\n",
    "    all_anm_Pre_R1_diff.append(anm_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c41ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diff_min = 0\n",
    "diff_max = 6\n",
    "nbins = 100\n",
    "bin_edges = np.linspace(diff_min, diff_max, num= nbins + 1)\n",
    "\n",
    "cumulative_fraction_all_s0 = []\n",
    "animal_diff_all_s0 = []\n",
    "for diff in all_anm_Pre_R1_diff:\n",
    "    anm_diff = np.abs(np.array(diff)[0,:]) \n",
    "    animal_diff_all_s0.append(anm_diff)\n",
    "    hist, _ = np.histogram(anm_diff, bins=bin_edges)\n",
    "    cumulative_fraction = np.cumsum(hist) / len(anm_diff) \n",
    "    cumulative_fraction_all_s0.append(cumulative_fraction)\n",
    "    \n",
    "    \n",
    "    \n",
    "cumulative_fraction_all_s_end = []\n",
    "animal_diff_all_end = []\n",
    "for diff in all_anm_Pre_R1_diff:\n",
    "    anm_diff = np.abs(np.array(diff)[-1,:])\n",
    "    animal_diff_all_end.append(anm_diff)\n",
    "    hist, _ = np.histogram(anm_diff, bins=bin_edges)\n",
    "    cumulative_fraction = np.cumsum(hist) / len(anm_diff) \n",
    "    cumulative_fraction_all_s_end.append(cumulative_fraction)\n",
    "    \n",
    "    \n",
    "cumulative_fraction_all_s0 = np.array(cumulative_fraction_all_s0)\n",
    "cumulative_fraction_all_s_end = np.array(cumulative_fraction_all_s_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d223d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the arrays\n",
    "animal_diff_all_s0_flat = np.concatenate(animal_diff_all_s0)\n",
    "animal_diff_all_end_flat= np.concatenate(animal_diff_all_end)\n",
    "\n",
    "# Remove any NaN values\n",
    "animal_diff_all_s0_flat = animal_diff_all_s0_flat [~np.isnan(animal_diff_all_s0_flat)]\n",
    "animal_diff_all_end_flat = animal_diff_all_end_flat[~np.isnan(animal_diff_all_end_flat)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb7ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard error of the mean for each array along the 0th dimension\n",
    "mean_s0 = np.mean(cumulative_fraction_all_s0, axis=0)\n",
    "sem_s0 = np.std(cumulative_fraction_all_s0, axis=0) / np.sqrt(cumulative_fraction_all_s0.shape[0])\n",
    "mean_s_end = np.mean(cumulative_fraction_all_s_end, axis=0)\n",
    "sem_s_end = np.std(cumulative_fraction_all_s_end, axis=0) / np.sqrt(cumulative_fraction_all_s_end.shape[0])\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(5, 5), dpi=600)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "axs.plot(bin_centers, mean_s0, color='black', label='Session 1')\n",
    "axs.fill_between(bin_centers, mean_s0 - sem_s0, mean_s0 + sem_s0, alpha=0.2, color='black')\n",
    "axs.plot(bin_centers, mean_s_end, color='purple', label='Last session')\n",
    "axs.fill_between(bin_centers, mean_s_end - sem_s_end, mean_s_end + sem_s_end, alpha=0.2, color='purple')\n",
    "\n",
    "axs.set_xlabel('dF/F difference in Pre-R1', fontsize=18)\n",
    "axs.set_ylabel('Cumulative fraction of cells', fontsize=18)\n",
    "axs.set_xlim([0, 4])\n",
    "axs.set_ylim([0, 1.05])\n",
    "axs.tick_params(labelsize=15)\n",
    "\n",
    "axs.legend(fontsize=15)\n",
    "plt.savefig('stage_3_to_4.pdf', format='pdf', dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b93bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "U, p_value_U = stats.mannwhitneyu(animal_diff_all_s0_flat, animal_diff_all_end_flat, alternative='two-sided')\n",
    "\n",
    "# Print the Mann-Whitney U result\n",
    "print(\"Mann-Whitney U statistic:\", U)\n",
    "print(\"Mann-Whitney U p-value:\", p_value_U)\n",
    "if p_value_U == 0:\n",
    "    print(\"Mann-Whitney U p-value is less than the precision of Python's floating-point arithmetic (typically around 1e-16 to 1e-308).\")\n",
    "else:\n",
    "    print(\"Mann-Whitney U p-value:\", p_value_U)\n",
    "\n",
    "# Perform the Wilcoxon Rank Sum test\n",
    "W, p_value_W = stats.ranksums(animal_diff_all_s0_flat, animal_diff_all_end_flat)\n",
    "\n",
    "# Print the Wilcoxon Rank Sum result\n",
    "print(\"Wilcoxon Rank Sum statistic:\", W)\n",
    "print(\"Wilcoxon Rank Sum p-value:\", p_value_W)\n",
    "if p_value_W == 0:\n",
    "    print(\"Wilcoxon Rank Sum p-value is less than the precision of Python's floating-point arithmetic (typically around 1e-16 to 1e-308).\")\n",
    "else:\n",
    "    print(\"Wilcoxon Rank Sum p-value:\", p_value_W)\n",
    "\n",
    "# Print statement about statistical significance \n",
    "print(\"If the p-value is less than 0.05, the Wilcoxon rank-sum test shows a statistically significant difference between the two groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f127e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ind = Pre_R1_region_ind_all[2][np.argsort(np.abs(all_anm_Pre_R1_diff[2][-1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c66fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load stored place field analysis for each day\n",
    "zarr_file = zarr.open(f'/.../placefields/Tyche-A7-SetA.zarr-PF.zarr', mode=\"r\")\n",
    "\n",
    "num_A_days = len(zarr_file[f'Cue Set A/1/excl_no_response/'])\n",
    "\n",
    "range_A = range(num_A_days)\n",
    "criteria = 'putative'\n",
    "\n",
    "pf_all_T1 = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "pf_all_T2 = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()] for i in range_A]\n",
    "\n",
    "binF_T1 = [zarr_file[f'Cue Set A/1/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "binF_T2 = [zarr_file[f'Cue Set A/2/excl_no_response/{i}/{criteria}'][()]['binF'] for i in range_A]\n",
    "\n",
    "binF_T1_all = np.array(binF_T1).T\n",
    "binF_T2_all = np.array(binF_T2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30425220",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cell_array = sorted_ind[-200:]\n",
    "session_range = np.arange(9)\n",
    "# Determine the number of rows and columns for the subplots\n",
    "num_cols = 10\n",
    "num_rows = int(np.ceil(len(cell_array) / num_cols ))\n",
    "\n",
    "x_start = 24\n",
    "x_end = 27\n",
    "vmax = 4\n",
    "fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(30, 4*num_rows), dpi=300)\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < len(cell_array):\n",
    "        index = cell_array[i]\n",
    "        stacked_Near_Far = np.hstack((binF_T1_all[:,index,:],binF_T2_all[:,index,:])).T\n",
    "        im = ax.imshow(stacked_Near_Far, aspect='auto', cmap='jet', vmin=0, vmax=vmax, interpolation=None)\n",
    "        ax.set_title(f\"Cell {index}\")\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        ax.axvline(x=x_start, linestyle='--', color='white', linewidth=1)\n",
    "        ax.axvline(x=x_end, linestyle='--', color='white', linewidth=1)\n",
    "        ax.axhline(y=9, linestyle='--', color='white', linewidth=1)\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b455a0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import figrid as fg\n",
    "\n",
    "cell_num = [2638,3328]\n",
    "\n",
    "x_start = 24*5\n",
    "x_end = 27*5\n",
    "\n",
    "vmin = 0\n",
    "vmax = 4\n",
    "region_marker_opacity = 0.1\n",
    "dpi = 600\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(4,6), dpi=dpi, facecolor='white', sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    q,r = divmod(i, 2) \n",
    "    # plot heatmap.\n",
    "    if r == 0:\n",
    "        x_extent = (0, 230,binF_T1_all[:,cell_num[q],:].T.shape[0],0)\n",
    "        h = ax.imshow(binF_T1_all[:,cell_num[q],:].T, aspect='auto', cmap='jet', vmin=vmin, vmax=vmax, interpolation=None, extent=x_extent)\n",
    "        ax.set_title(f'Cell {cell_num[q]}', fontsize=12)\n",
    "    if r == 1:\n",
    "        x_extent = (0, 230,binF_T2_all[:,cell_num[q],:].T.shape[0],0)\n",
    "        h = ax.imshow(binF_T2_all[:,cell_num[q],:].T, aspect='auto', cmap='jet', vmin=vmin, vmax=vmax, interpolation=None, extent=x_extent)\n",
    "        ax.set_title(f'Cell {cell_num[q]}', fontsize=12)\n",
    "\n",
    "    # format axis.\n",
    "    print(i)\n",
    "    if i >= 2:\n",
    "        ax.set_xlabel('Position (cm)', fontsize=12)\n",
    "    if i % 2 == 0:\n",
    "        ax.set_ylabel('Session number', fontsize=12)\n",
    "        y_ticks = np.arange(0.5, 9.5)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        ax.set_yticklabels(ylabels)\n",
    "        \n",
    "    else:\n",
    "        ax.set_ylabel('', fontsize=12)\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    #ax.set_title(f'Cell {cell_num[i]}', fontsize=12)\n",
    "#     ax.axvline(x=x_start, linestyle='--', color='white', linewidth=1)\n",
    "#     ax.axvline(x=x_end, linestyle='--', color='white', linewidth=1)\n",
    "\n",
    "# colorbar.\n",
    "cbar = fig.colorbar(h, ax=axs.ravel().tolist(), label='dF/F0')\n",
    "cbar.ax.set_position([0.99, 0.1, 0.02, 0.8])\n",
    "cbar.ax.set_ylabel('dF/F0', fontsize=12)\n",
    "cbar.ax.yaxis.set_tick_params(labelsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Example_stage_3_4_cells.pdf', format='pdf', dpi=500)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
