{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9892fa-b54a-44ca-9435-87200709db69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vr2p\n",
    "from scipy.io import loadmat\n",
    "import gcsfs\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import warnings\n",
    "from skimage import registration\n",
    "import skimage\n",
    "from skimage import metrics, transform\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import interpolate, ndimage, stats\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import cm,colors,colormaps\n",
    "from skimage.exposure import rescale_intensity\n",
    "import seaborn as sns\n",
    "from suite2p.registration import rigid\n",
    "from scipy.fftpack import fft2, ifft2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2541e068-8d8d-4057-b672-5f50d98c1431",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d61c95-358a-4733-93e9-354cc38f1096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "# Helper functions\n",
    "##\n",
    "\n",
    "def array2rgb( array, disp_range,cmap):\n",
    "    array = rescale_intensity(array,in_range = tuple(disp_range),out_range=(0,1)).astype(float)\n",
    "    return cmap(array)\n",
    "\n",
    "def add_weighted(im,weight):\n",
    "    for i in range(3):\n",
    "        im[:,:,i] *= weight\n",
    "    return im\n",
    "\n",
    "def plot_heatmap(im, d_range, colormap):\n",
    "    heatmap_im = array2rgb( im, d_range,colormap)\n",
    "    heatmap_im = add_weighted(heatmap_im,base_im)\n",
    "    heatmap_im = np.ma.masked_where(np.isnan(heatmap_im), heatmap_im)\n",
    "    #plot\n",
    "    fig = plt.figure(figsize=(2.5,2.5),dpi=300)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    # plot img.\n",
    "    ax.imshow( heatmap_im, origin='lower',extent=extent, \n",
    "              interpolation='none', vmin=0, vmax=1) # correct non uniform aspect ratio.\n",
    "    ax.axis('off')\n",
    "    ax.set_xlim(fov_mm[0])\n",
    "    ax.set_ylim(fov_mm[1])\n",
    "    # set title\n",
    "    title_str = f'session (zero based): {session}\\n'\n",
    "    title_str += f'fov size: {fov_size_mm} mm\\n'\n",
    "    title_str += f'{img_type} range: {display_range[0]}-{display_range[1]}\\n'\n",
    "    title_str += f'heatmap range: {d_range[0]}-{d_range[1]}'\n",
    "    fig.suptitle(title_str,fontsize = 2.5)\n",
    "    \n",
    "def get_registration_stack(animal,data, session):\n",
    "    # get date of sessions for look up\n",
    "    date_str = data.vr[session].info['date_time'][:10]\n",
    "    date_str = date_str.replace('-','_')\n",
    "    # find right folder.\n",
    "    fs = gcsfs.GCSFileSystem(project='sprustonlab-meso')\n",
    "    dir_list = [item['name']for item in fs.listdir(f'gs://linear-2ac/motion/Tyche-{animal}/{date_str}') if item['type']=='directory']\n",
    "    assert len(dir_list)==1, f'Found multiple sessions for {animal} {date_str}'\n",
    "    # get motion file.\n",
    "    with fs.open(f'gs://{dir_list[0]}/MotionEstimator.me', 'rb') as handle:\n",
    "        motion_data = loadmat(handle,simplify_cells=True)\n",
    "    # get stacks for each stripe.\n",
    "    num_stripes = len(motion_data['c'])\n",
    "    stripes = []\n",
    "    for stripe in motion_data['c']:\n",
    "        stripe_data = np.stack([ plane for plane in stripe['roiData']['imageData']],axis=2)\n",
    "        stripe_data = np.transpose(stripe_data,(1,0,2))\n",
    "        stripes.append(stripe_data)\n",
    "    # get offsets in pixels\n",
    "    offset_pix = [] \n",
    "    for stripe_data in motion_data['c']:\n",
    "        scan_field = stripe_data['roiData']['hRoi']['scanfields']\n",
    "        offset = [ scan_field['pixelToRefTransform'][0,2],scan_field['pixelToRefTransform'][1,2]]\n",
    "        conversion_factor = [ scan_field['pixelToRefTransform'][0,0],scan_field['pixelToRefTransform'][1,1]]\n",
    "        offset_pix.append([offset[0]/conversion_factor[0], offset[1]/conversion_factor[1] ])\n",
    "    offset_pix = np.array(offset_pix)\n",
    "    # get stripe order on FOV\n",
    "    stripe_order = offset_pix[:,0].argsort()\n",
    "    stripes = [ stripes[i] for i in stripe_order]\n",
    "    # get original image where stripes are in one FOV.\n",
    "    original_img = data.images.original[0]['mean_img'] # image is in yx\n",
    "    # create new image that will hold entire FOV stack.\n",
    "    reg_stack = np.zeros((original_img.shape[0], original_img.shape[1], stripes[0].shape[2]))\n",
    "    # get location of vertical lines trhough images to catch location of stripes.\n",
    "    stripe_width = stripes[1].shape[1] # stripes are in yx\n",
    "    stripe_mid_points = np.arange(int(stripe_width/2), original_img.shape[1], stripe_width)\n",
    "    # Check pixel location along stripes\n",
    "    start_x = 0\n",
    "    for i_stripe, stripe_mid_point in enumerate(stripe_mid_points):\n",
    "        values = original_img[:,stripe_mid_point]\n",
    "        y_pixels = np.argwhere(values>0).astype(int)\n",
    "        y_range = [min(y_pixels),max(y_pixels)+1]\n",
    "        # fill in data.\n",
    "        reg_stack[int(y_range[0]):int(y_range[1]),start_x:start_x+stripe_width,:] = stripes[i_stripe]\n",
    "        start_x+=stripe_width\n",
    "    return reg_stack    \n",
    "\n",
    "def filter_nan_gaussian_conserving(arr, sigma):\n",
    "    \"\"\"Apply a gaussian filter to an array with nans.\n",
    "\n",
    "    Intensity is only shifted between not-nan pixels and is hence conserved.\n",
    "    The intensity redistribution with respect to each single point\n",
    "    is done by the weights of available pixels according\n",
    "    to a gaussian distribution.\n",
    "    All nans in arr, stay nans in gauss.\n",
    "    \"\"\"\n",
    "    nan_msk = np.isnan(arr)\n",
    "\n",
    "    loss = np.zeros(arr.shape)\n",
    "    loss[nan_msk] = 1\n",
    "    loss = ndimage.gaussian_filter(\n",
    "            loss, sigma=sigma, mode='constant', cval=1)\n",
    "\n",
    "    gauss = arr.copy()\n",
    "    gauss[nan_msk] = 0\n",
    "    gauss = ndimage.gaussian_filter(\n",
    "            gauss, sigma=sigma, mode='constant', cval=0)\n",
    "    gauss[nan_msk] = np.nan\n",
    "\n",
    "    gauss += loss * arr\n",
    "\n",
    "    return gauss\n",
    "\n",
    "# ratio between y and x should be 1.5\n",
    "def get_offsets(data,session, stack, bin_size = [300,450], shift = [30,45],min_rois=200,verbose=False):\n",
    "    img = data.images.original[session]['mean_img']\n",
    "    rois = data.cells.multi_session.original[session]\n",
    "    # bin size is assumed yx\n",
    "    # check image size match (YX) or (height width)\n",
    "    assert (img.shape[0]==stack.shape[0]) & (img.shape[1]==stack.shape[1]), 'Image sizes did not match'\n",
    "    # Get roi centers.\n",
    "    centers = np.vstack([roi['med'] for roi in rois]) # YX\n",
    "    \n",
    "    # bin image.\n",
    "    offset_data = []\n",
    "    for y, y_start in  enumerate(tqdm(np.arange(0,img.shape[0],shift[0]).astype(int),disable=verbose==False)):\n",
    "        y_end = y_start+bin_size[0]\n",
    "        if y_end>img.shape[0]: y_end=img.shape[0]\n",
    "        for x, x_start in enumerate(np.arange(0,img.shape[1],shift[1]).astype(int)):\n",
    "            x_end = x_start+bin_size[1]\n",
    "            if x_end>img.shape[1]: x_end=img.shape[1]             \n",
    "            #print('y:',y_start,'-',y_end)\n",
    "            # Check if there are ROIs in this bin\n",
    "            num_rois_in_bin = sum( (centers[:,0]>y_start) & (centers[:,0]<y_end) & \n",
    "                                     (centers[:,1]>x_start) & (centers[:,1]<x_end))\n",
    "            if num_rois_in_bin>=min_rois:\n",
    "                # Perform cross correlation calculation at all z levels\n",
    "                z_img = img[y_start:y_end,x_start:x_end]\n",
    "                z_img = rigid.phasecorr_reference(z_img, smooth_sigma=1)\n",
    "                \n",
    "                scores = []\n",
    "                for z in range(stack.shape[2]):\n",
    "                    z_reg_img = stack[y_start:y_end,x_start:x_end,z]\n",
    "                    z_reg_img = rigid.phasecorr_reference(z_reg_img, smooth_sigma=1)\n",
    "                    # check sizes match\n",
    "                    assert (z_img.shape[0]==z_reg_img.shape[0]) & (z_img.shape[1]==z_reg_img.shape[1]), 'correlation images did not match in size'\n",
    "                    # Convolve transformed images using multiplication\n",
    "                    f_conj = np.conj(z_reg_img) * z_img\n",
    "\n",
    "                    # Return to the spatial domain with an inverse FFT\n",
    "                    corr = np.abs(ifft2(f_conj))\n",
    "\n",
    "                    # Rearrange the normalized cross-correlation matrix so that the zero frequency is in the middle of the matrix\n",
    "                    corr = np.max(np.fft.fftshift(corr))\n",
    "                    #shit_pix, corr = cv2.phaseCorrelate(z_img, z_reg_img)\n",
    "                    scores.append(corr)\n",
    "                # calculate max offset \n",
    "                offset = 12-np.argmax(gaussian_filter1d(scores,2))\n",
    "                y_pix, x_pix = np.mean([y_start,y_end]), np.mean([x_start,x_end])\n",
    "                y_um, x_um = y_pix*pix_size[0], x_pix*pix_size[1]\n",
    "                offset_data.append({'y':int(y),'x':int(x),'y_um': y_um, 'x_um':x_um, 'y_pix': y_pix, 'x_pix': x_pix,'offset':offset})\n",
    "    offset_data = pd.DataFrame(offset_data)\n",
    "    # Generate image.\n",
    "    res_im = np.full((offset_data.y.max()+1, offset_data.x.max()+1),None).astype(float)\n",
    "    res_im[offset_data.y, offset_data.x] = offset_data.offset\n",
    "    \n",
    "    return res_im, offset_data\n",
    "\n",
    "def gen_mask_im(im, threshold=0.08):\n",
    "    mask_im = (transform.resize(im,(30,45))>threshold)\n",
    "    mask_im = ndimage.binary_fill_holes(mask_im).astype('float')\n",
    "    mask_im = np.pad(mask_im,5)\n",
    "    # resize to baseim size with added padding.\n",
    "    mask_im = transform.resize(mask_im,(im.shape[0]*(1+(5/30)),\n",
    "                                        im.shape[1]*(1+(5/45))),\n",
    "                               mode='edge',anti_aliasing=True,anti_aliasing_sigma=1,\n",
    "                                   preserve_range=False,\n",
    "                                   order=1)>0.15\n",
    "    # remove extra padding\n",
    "    crop_loc =  [int((5/30)*im.shape[0]/2),\n",
    "                  int((5/45)*im.shape[1]/2)]\n",
    "    mask_im = mask_im[crop_loc[0]:crop_loc[0]+im.shape[0],\n",
    "                       crop_loc[1]:crop_loc[1]+im.shape[1]]\n",
    "    return mask_im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03254d78-4f3f-4d03-a9ca-8e5e18c728b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d82c72-c76e-4802-b397-b1af7f260e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "animal = 'A7'\n",
    "pix_size = [2,1.333]\n",
    "# load data.\n",
    "#data = vr2p.ExperimentData(f'gs://linear-2ac/Set A/Tyche-{animal}-SetA.zarr')\n",
    "data = vr2p.ExperimentData(f'gs://linear-2ac/Set A-E/Tyche-{animal}')\n",
    "reg_stack = get_registration_stack(animal,data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42881a52-edc0-4ed7-bf1b-e3595ca7c18c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c2aaafa22a410fb059b69400c26632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ offset max: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mnanmax(filt_im)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.02f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, min \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mnanmin(filt_im)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.02f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# get session fovs (zero indexed sessions)\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[43mgen_fov_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m gen_fov_image(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     44\u001b[0m gen_fov_image(\u001b[38;5;241m9\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mgen_fov_image\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m     16\u001b[0m fov_mm \u001b[38;5;241m=\u001b[39m [[fov_origin_mm[\u001b[38;5;241m0\u001b[39m],fov_origin_mm[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m fov_size_mm],\n\u001b[1;32m     17\u001b[0m         [fov_origin_mm[\u001b[38;5;241m1\u001b[39m],fov_origin_mm[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m fov_size_mm]] \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# get offset data.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m res_im, offset_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_offsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_stack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_rois\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m filt_im \u001b[38;5;241m=\u001b[39m filter_nan_gaussian_conserving(res_im,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m resized_im \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mresize(filt_im, base_im\u001b[38;5;241m.\u001b[39mshape,anti_aliasing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 137\u001b[0m, in \u001b[0;36mget_offsets\u001b[0;34m(data, session, stack, bin_size, shift, min_rois, verbose)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(stack\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m    136\u001b[0m     z_reg_img \u001b[38;5;241m=\u001b[39m stack[y_start:y_end,x_start:x_end,z]\n\u001b[0;32m--> 137\u001b[0m     z_reg_img \u001b[38;5;241m=\u001b[39m \u001b[43mrigid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphasecorr_reference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_reg_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# check sizes match\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (z_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m==\u001b[39mz_reg_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m&\u001b[39m (z_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m==\u001b[39mz_reg_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrelation images did not match in size\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/vr2p/lib/python3.8/site-packages/suite2p/registration/rigid.py:63\u001b[0m, in \u001b[0;36mphasecorr_reference\u001b[0;34m(refImg, smooth_sigma)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03mReturns reference image fft'ed and complex conjugate and multiplied by gaussian filter in the fft domain,\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mwith standard deviation 'smooth_sigma' computes fft'ed reference image for phasecorr.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mcfRefImg : 2D array, complex64\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m cfRefImg \u001b[38;5;241m=\u001b[39m complex_fft2(img\u001b[38;5;241m=\u001b[39mrefImg)\n\u001b[0;32m---> 63\u001b[0m cfRefImg \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1e-5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabsolute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfRefImg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     64\u001b[0m cfRefImg \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m gaussian_fft(smooth_sigma, cfRefImg\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], cfRefImg\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cfRefImg\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplex64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "session=20\n",
    "offset_range = [-10,10]\n",
    "img_type = 'mean_img'\n",
    "display_range = [250,1800]\n",
    "fov_size_mm = 1.55\n",
    "fov_origin_mm = [0.1,0.05] # left bottom origin.\n",
    "cmap = colormaps['PiYG']\n",
    "cmap.set_bad(color='black')\n",
    "\n",
    "def gen_fov_image(session):\n",
    "    # get base image of FOV\n",
    "    base_im = rescale_intensity(data.images.original[session][img_type],\n",
    "                                in_range = tuple(display_range), out_range=(0,1)).astype(float)\n",
    "    # fov crop in x -y\n",
    "    extent=[0,(base_im.shape[1]*pix_size[1])/1000, 0,(base_im.shape[0]*pix_size[0])/1000]\n",
    "    fov_mm = [[fov_origin_mm[0],fov_origin_mm[0] + fov_size_mm],\n",
    "            [fov_origin_mm[1],fov_origin_mm[1] + fov_size_mm]] \n",
    "\n",
    "    # get offset data.\n",
    "    res_im, offset_data = get_offsets(data, session, reg_stack, verbose=True, min_rois=200 )\n",
    "    filt_im = filter_nan_gaussian_conserving(res_im,1)\n",
    "    resized_im = transform.resize(filt_im, base_im.shape,anti_aliasing=False)\n",
    "    # mask image.\n",
    "    mask_im = gen_mask_im(base_im,threshold=0.05)\n",
    "    masked_im = np.ma.masked_where(mask_im==False, resized_im)\n",
    "    #plot\n",
    "    fig = plt.figure(figsize=(2.5,2.5),dpi=300)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    # plot img.\n",
    "    ax.imshow( masked_im, origin='lower',extent=extent, \n",
    "            interpolation='none',cmap=cmap,vmin=offset_range[0],vmax=offset_range[1]) # correct non uniform aspect ratio.\n",
    "    ax.axis('off')\n",
    "    ax.set_xlim(fov_mm[0])\n",
    "    ax.set_ylim(fov_mm[1])\n",
    "    # set title\n",
    "    title_str = f'session (zero based): {session}\\n'\n",
    "    title_str += f'fov size: {fov_size_mm} mm\\n'\n",
    "    title_str += f'heatmap range: {offset_range[0]}-{offset_range [1]}'\n",
    "    fig.suptitle(title_str,fontsize = 2.5)\n",
    "    print(f'Z offset max: {np.nanmax(filt_im):.02f}, min {np.nanmin(filt_im):.02f}')\n",
    "# get session fovs (zero indexed sessions)\n",
    "gen_fov_image(1)\n",
    "gen_fov_image(4)\n",
    "gen_fov_image(9)\n",
    "gen_fov_image(14)\n",
    "gen_fov_image(24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
